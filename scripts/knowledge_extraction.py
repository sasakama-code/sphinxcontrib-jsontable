#!/usr/bin/env python3
"""
KPTåˆ†æã‹ã‚‰ãƒŠãƒ¬ãƒƒã‚¸æŠ½å‡ºãƒ»ç®¡ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Usage:
    # ã‚¿ã‚¹ã‚¯ç€æ‰‹å‰ãƒŠãƒ¬ãƒƒã‚¸ç¢ºèª (æ–°æ©Ÿèƒ½)
    python scripts/knowledge_extraction.py pre-check --task "Phase 3 PLaMo-Embedding-1Bçµ±åˆå®Ÿè£…"
    
    # KPTåˆ†æã‹ã‚‰ãƒŠãƒ¬ãƒƒã‚¸æŠ½å‡º
    python scripts/knowledge_extraction.py extract --kpt-file plan/analysis/kpt_analysis.md
    
    # ãƒŠãƒ¬ãƒƒã‚¸å“è³ªæ¤œè¨¼
    python scripts/knowledge_extraction.py validate --knowledge-dir knowledge/
    
    # è©³ç´°å“è³ªãƒ¬ãƒ“ãƒ¥ãƒ¼
    python scripts/knowledge_extraction.py review --knowledge-file knowledge/technical_architecture/rag_pipeline.md
"""

import argparse
import json
import os
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import hashlib

class KnowledgeExtractionRules:
    """KPTãƒŠãƒ¬ãƒƒã‚¸æŠ½å‡ºãƒ«ãƒ¼ãƒ«"""
    
    def __init__(self):
        self.extraction_criteria = {
            "technical_knowledge": {
                "minimum_success_rate": 0.80,
                "replication_potential": "high",
                "documentation_completeness": "comprehensive",
                "code_examples_available": True
            },
            "strategic_knowledge": {
                "measurable_impact": True,
                "decision_rationale_clear": True,
                "stakeholder_alignment": "achieved",
                "timeline_efficiency": 1.50  # 150%ä»¥ä¸Š
            },
            "process_knowledge": {
                "workflow_documentation": "complete",
                "quality_metrics": "defined",
                "automation_potential": "high",
                "scalability_proven": True
            }
        }
        
        self.knowledge_categories = {
            "technical_architecture": {
                "path": "knowledge/technical_architecture/",
                "description": "æŠ€è¡“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ»è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³",
                "examples": ["ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ", "ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ§‹æˆ", "APIè¨­è¨ˆ"]
            },
            "development_patterns": {
                "path": "knowledge/development_patterns/",
                "description": "é–‹ç™ºæ‰‹æ³•ãƒ»ãƒ—ãƒ­ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³",
                "examples": ["ãƒ†ã‚¹ãƒˆæˆ¦ç•¥", "å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³", "å“è³ªä¿è¨¼"]
            },
            "business_insights": {
                "path": "knowledge/business_insights/",
                "description": "ãƒ“ã‚¸ãƒã‚¹æ´å¯Ÿãƒ»å¸‚å ´åˆ†æ",
                "examples": ["å¸‚å ´æˆ¦ç•¥", "ç«¶åˆåˆ†æ", "ROIåˆ†æ"]
            },
            "project_management": {
                "path": "knowledge/project_management/",
                "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ãƒ»æ„æ€æ±ºå®š",
                "examples": ["è¨ˆç”»æ‰‹æ³•", "ãƒªã‚¹ã‚¯ç®¡ç†", "ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ç®¡ç†"]
            },
            "lessons_learned": {
                "path": "knowledge/lessons_learned/",
                "description": "æ•™è¨“ãƒ»æ”¹å–„ç‚¹",
                "examples": ["æˆåŠŸè¦å› ", "å¤±æ•—åˆ†æ", "æ”¹å–„ææ¡ˆ"]
            }
        }
        
        self.security_levels = {
            "public": {
                "description": "å…¬é–‹å¯èƒ½",
                "gitignore": False,
                "examples": ["ä¸€èˆ¬çš„æŠ€è¡“ãƒ‘ã‚¿ãƒ¼ãƒ³", "ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹è²¢çŒ®"]
            },
            "internal": {
                "description": "å†…éƒ¨é™å®š",
                "gitignore": True,
                "examples": ["ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰å®Ÿè£…", "çµ„ç¹”å†…å­¦ç¿’"]
            },
            "confidential": {
                "description": "æ©Ÿå¯†",
                "gitignore": True,
                "examples": ["æˆ¦ç•¥åˆ†æ", "ç«¶åˆæƒ…å ±", "åç›Šãƒ‡ãƒ¼ã‚¿"]
            },
            "restricted": {
                "description": "åˆ¶é™",
                "gitignore": True,
                "examples": ["å€‹äººæƒ…å ±", "æœªç™ºè¡¨æƒ…å ±", "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼æ©Ÿå¯†"]
            }
        }

class KPTAnalyzer:
    """KPTåˆ†æãƒ•ã‚¡ã‚¤ãƒ«è§£æ"""
    
    def __init__(self):
        self.kpt_patterns = {
            "keep_section": r"##\s*ğŸŸ¢\s*\*\*Keep[^#]*?(?=##|\Z)",
            "problem_section": r"##\s*ğŸ”´\s*\*\*Problem[^#]*?(?=##|\Z)",
            "try_section": r"##\s*ğŸš€\s*\*\*Try[^#]*?(?=##|\Z)",
            "success_metrics": r"([0-9]+(?:\.[0-9]+)?%|[0-9]+(?:\.[0-9]+)?å€|[0-9]+(?:\.[0-9]+)?x)",
            "implementation_details": r"```(?:python|javascript|bash|sql)(.*?)```",
            "quantitative_results": r"([0-9,]+(?:\.[0-9]+)?)\s*(è¡Œ|ä»¶|ç§’|ãƒ¶æœˆ|%)"
        }
    
    def parse_kpt_file(self, kpt_file_path: str) -> Dict[str, Any]:
        """KPTãƒ•ã‚¡ã‚¤ãƒ«è§£æ"""
        
        with open(kpt_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        analysis_result = {
            "file_path": kpt_file_path,
            "extraction_date": datetime.now().isoformat(),
            "sections": {},
            "success_metrics": [],
            "implementation_details": [],
            "quantitative_results": []
        }
        
        # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³æŠ½å‡º
        for section_name, pattern in self.kpt_patterns.items():
            if section_name.endswith('_section'):
                matches = re.findall(pattern, content, re.DOTALL | re.IGNORECASE)
                if matches:
                    analysis_result["sections"][section_name] = matches[0]
        
        # æˆåŠŸæŒ‡æ¨™æŠ½å‡º
        success_metrics = re.findall(self.kpt_patterns["success_metrics"], content)
        analysis_result["success_metrics"] = success_metrics
        
        # å®Ÿè£…è©³ç´°æŠ½å‡º
        implementation_details = re.findall(self.kpt_patterns["implementation_details"], content, re.DOTALL)
        analysis_result["implementation_details"] = implementation_details
        
        # å®šé‡çš„çµæœæŠ½å‡º
        quantitative_results = re.findall(self.kpt_patterns["quantitative_results"], content)
        analysis_result["quantitative_results"] = quantitative_results
        
        return analysis_result
    
    def extract_knowledge_candidates(self, analysis_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ãƒŠãƒ¬ãƒƒã‚¸å€™è£œæŠ½å‡º"""
        
        candidates = []
        
        # Keepé …ç›®ã‹ã‚‰ãƒŠãƒ¬ãƒƒã‚¸æŠ½å‡º
        if "keep_section" in analysis_result["sections"]:
            keep_content = analysis_result["sections"]["keep_section"]
            keep_items = self._parse_keep_items(keep_content)
            
            for item in keep_items:
                if self._meets_extraction_criteria(item):
                    candidate = {
                        "type": "success_pattern",
                        "source_section": "keep",
                        "title": item.get("title", "Unknown"),
                        "content": item.get("content", ""),
                        "success_evidence": item.get("evidence", []),
                        "replication_potential": self._assess_replication_potential(item),
                        "suggested_category": self._suggest_knowledge_category(item),
                        "security_level": self._assess_security_level(item)
                    }
                    candidates.append(candidate)
        
        # Tryé …ç›®ã‹ã‚‰æ”¹å–„ææ¡ˆæŠ½å‡º
        if "try_section" in analysis_result["sections"]:
            try_content = analysis_result["sections"]["try_section"]
            try_items = self._parse_try_items(try_content)
            
            for item in try_items:
                candidate = {
                    "type": "improvement_opportunity",
                    "source_section": "try",
                    "title": item.get("title", "Unknown"),
                    "content": item.get("content", ""),
                    "expected_impact": item.get("impact", ""),
                    "implementation_approach": item.get("approach", ""),
                    "suggested_category": self._suggest_knowledge_category(item),
                    "security_level": self._assess_security_level(item)
                }
                candidates.append(candidate)
        
        return candidates
    
    def _parse_keep_items(self, keep_content: str) -> List[Dict[str, Any]]:
        """Keepé …ç›®è§£æ"""
        
        # é …ç›®åˆ†å‰²ï¼ˆ### ã§å§‹ã¾ã‚‹é …ç›®ï¼‰
        items = re.split(r'\n###\s*\*?\*?([^#\n]+)', keep_content)
        
        parsed_items = []
        for i in range(1, len(items), 2):
            if i + 1 < len(items):
                title = items[i].strip()
                content = items[i + 1].strip()
                
                # æˆåŠŸè¨¼æ‹ æŠ½å‡º
                evidence = re.findall(r'\*\*å®Ÿç¸¾\*\*:(.*?)(?=\*\*|$)', content, re.DOTALL)
                
                parsed_items.append({
                    "title": title,
                    "content": content,
                    "evidence": [e.strip() for e in evidence]
                })
        
        return parsed_items
    
    def _parse_try_items(self, try_content: str) -> List[Dict[str, Any]]:
        """Tryé …ç›®è§£æ"""
        
        items = re.split(r'\n###\s*\*?\*?([^#\n]+)', try_content)
        
        parsed_items = []
        for i in range(1, len(items), 2):
            if i + 1 < len(items):
                title = items[i].strip()
                content = items[i + 1].strip()
                
                # æœŸå¾…åŠ¹æœæŠ½å‡º
                impact = re.findall(r'\*\*æœŸå¾…åŠ¹æœ\*\*:(.*?)(?=\*\*|$)', content, re.DOTALL)
                approach = re.findall(r'\*\*ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ\*\*:(.*?)(?=\*\*|$)', content, re.DOTALL)
                
                parsed_items.append({
                    "title": title,
                    "content": content,
                    "impact": impact[0].strip() if impact else "",
                    "approach": approach[0].strip() if approach else ""
                })
        
        return parsed_items
    
    def _meets_extraction_criteria(self, item: Dict[str, Any]) -> bool:
        """æŠ½å‡ºåŸºæº–ãƒã‚§ãƒƒã‚¯"""
        
        # æˆåŠŸè¨¼æ‹ ã®æœ‰ç„¡
        if not item.get("evidence"):
            return False
        
        # å…·ä½“çš„ãªå®Ÿè£…è©³ç´°ã®æœ‰ç„¡
        content = item.get("content", "")
        if not re.search(r'```|å®Ÿè£…|ã‚³ãƒ¼ãƒ‰|æ‰‹æ³•', content):
            return False
        
        # å®šé‡çš„æŒ‡æ¨™ã®æœ‰ç„¡
        if not re.search(r'[0-9]+(?:\.[0-9]+)?[%å€x]', content):
            return False
        
        return True
    
    def _assess_replication_potential(self, item: Dict[str, Any]) -> str:
        """å†ç¾å¯èƒ½æ€§è©•ä¾¡"""
        
        content = item.get("content", "")
        
        # å…·ä½“çš„ãªæ‰‹é †ãƒ»ã‚³ãƒ¼ãƒ‰ã®æœ‰ç„¡
        has_concrete_steps = bool(re.search(r'```|æ‰‹é †|ã‚¹ãƒ†ãƒƒãƒ—|å®Ÿè£…', content))
        
        # å‰ææ¡ä»¶ã®æ˜è¨˜
        has_prerequisites = bool(re.search(r'å‰æ|æ¡ä»¶|è¦ä»¶', content))
        
        # æˆåŠŸæŒ‡æ¨™ã®å®šç¾©
        has_metrics = bool(re.search(r'æŒ‡æ¨™|ãƒ¡ãƒˆãƒªã‚¯ã‚¹|æ¸¬å®š', content))
        
        score = sum([has_concrete_steps, has_prerequisites, has_metrics])
        
        if score >= 3:
            return "high"
        elif score >= 2:
            return "medium"
        else:
            return "low"
    
    def _suggest_knowledge_category(self, item: Dict[str, Any]) -> str:
        """ãƒŠãƒ¬ãƒƒã‚¸ã‚«ãƒ†ã‚´ãƒªæ¨å®š"""
        
        content = item.get("content", "") + " " + item.get("title", "")
        content_lower = content.lower()
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
        category_keywords = {
            "technical_architecture": ["ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£", "è¨­è¨ˆ", "API", "ã‚·ã‚¹ãƒ†ãƒ ", "çµ±åˆ", "ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"],
            "development_patterns": ["ãƒ†ã‚¹ãƒˆ", "å®Ÿè£…", "é–‹ç™º", "ã‚³ãƒ¼ãƒ‰", "å“è³ª", "ãƒ‘ã‚¿ãƒ¼ãƒ³"],
            "business_insights": ["å¸‚å ´", "ç«¶åˆ", "æˆ¦ç•¥", "ROI", "åç›Š", "ãƒ“ã‚¸ãƒã‚¹"],
            "project_management": ["è¨ˆç”»", "æ„æ€æ±ºå®š", "ç®¡ç†", "ãƒªã‚¹ã‚¯", "ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼"],
            "lessons_learned": ["æ•™è¨“", "æ”¹å–„", "å¤±æ•—", "æˆåŠŸè¦å› ", "å­¦ç¿’"]
        }
        
        scores = {}
        for category, keywords in category_keywords.items():
            score = sum(1 for keyword in keywords if keyword in content_lower)
            scores[category] = score
        
        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®ã‚«ãƒ†ã‚´ãƒªã‚’è¿”ã™
        return max(scores.items(), key=lambda x: x[1])[0]
    
    def _assess_security_level(self, item: Dict[str, Any]) -> str:
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ™ãƒ«è©•ä¾¡"""
        
        content = item.get("content", "") + " " + item.get("title", "")
        content_lower = content.lower()
        
        # æ©Ÿå¯†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        restricted_keywords = ["å€‹äººæƒ…å ±", "æ©Ÿå¯†", "ç§˜å¯†", "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", "api key"]
        confidential_keywords = ["æˆ¦ç•¥", "ç«¶åˆ", "åç›Š", "roi", "å¸‚å ´åˆ†æ", "ç‰¹è¨±"]
        internal_keywords = ["å†…éƒ¨", "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰", "çµ„ç¹”", "ãƒãƒ¼ãƒ "]
        
        if any(keyword in content_lower for keyword in restricted_keywords):
            return "restricted"
        elif any(keyword in content_lower for keyword in confidential_keywords):
            return "confidential"
        elif any(keyword in content_lower for keyword in internal_keywords):
            return "internal"
        else:
            return "public"

class KnowledgeDocumentGenerator:
    """ãƒŠãƒ¬ãƒƒã‚¸æ–‡æ›¸ç”Ÿæˆ"""
    
    def __init__(self):
        self.document_template = """# ğŸ¯ {title}

**æŠ½å‡ºå…ƒ**: KPTåˆ†æ ({source_file})  
**æ¤œè¨¼æœŸé–“**: {validation_period}  
**å®Ÿè¨¼åŠ¹æœ**: {proven_effects}

---

## ğŸ“‹ æ¦‚è¦

{overview}

## ğŸ¯ æ ¸å¿ƒåŸå‰‡

{core_principles}

## ğŸ”§ å®Ÿè£…è©³ç´°

{implementation_details}

## ğŸ“Š æˆåŠŸæŒ‡æ¨™

{success_metrics}

## ğŸ¯ é©ç”¨æ¡ä»¶

{application_conditions}

## ğŸ”„ ç¶™ç¶šçš„æ”¹å–„

{continuous_improvement}

---

## ğŸ† çµè«–

{conclusion}
"""
    
    def generate_knowledge_document(
        self, 
        candidate: Dict[str, Any], 
        kpt_analysis: Dict[str, Any]
    ) -> str:
        """ãƒŠãƒ¬ãƒƒã‚¸æ–‡æ›¸ç”Ÿæˆ"""
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¤‰æ•°ã®æº–å‚™
        template_vars = {
            "title": candidate.get("title", "Unknown Knowledge"),
            "source_file": os.path.basename(kpt_analysis.get("file_path", "unknown")),
            "validation_period": self._extract_validation_period(kpt_analysis),
            "proven_effects": self._extract_proven_effects(candidate),
            "overview": self._generate_overview(candidate),
            "core_principles": self._extract_core_principles(candidate),
            "implementation_details": self._extract_implementation_details(candidate),
            "success_metrics": self._extract_success_metrics(candidate),
            "application_conditions": self._generate_application_conditions(candidate),
            "continuous_improvement": self._generate_improvement_section(candidate),
            "conclusion": self._generate_conclusion(candidate)
        }
        
        return self.document_template.format(**template_vars)
    
    def _extract_validation_period(self, kpt_analysis: Dict[str, Any]) -> str:
        """æ¤œè¨¼æœŸé–“æŠ½å‡º"""
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜æŠ½å‡ºã‚’è©¦è¡Œ
        file_path = kpt_analysis.get("file_path", "")
        date_match = re.search(r'(\d{4}-\d{2}-\d{2})', file_path)
        
        if date_match:
            return date_match.group(1)
        else:
            return datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    
    def _extract_proven_effects(self, candidate: Dict[str, Any]) -> str:
        """å®Ÿè¨¼åŠ¹æœæŠ½å‡º"""
        
        content = candidate.get("content", "")
        
        # å®šé‡çš„åŠ¹æœã‚’æ¤œç´¢
        effects = re.findall(r'([0-9]+(?:\.[0-9]+)?[%å€x][^ã€‚]*)', content)
        
        if effects:
            return "ã€".join(effects[:3])  # æœ€å¤§3ã¤ã®åŠ¹æœ
        else:
            return "å®šæ€§çš„æ”¹å–„åŠ¹æœç¢ºèªæ¸ˆã¿"
    
    def _generate_overview(self, candidate: Dict[str, Any]) -> str:
        """æ¦‚è¦ç”Ÿæˆ"""
        
        content = candidate.get("content", "")
        
        # æœ€åˆã®æ®µè½ã‚’æ¦‚è¦ã¨ã—ã¦ä½¿ç”¨
        paragraphs = content.split('\n\n')
        overview = paragraphs[0] if paragraphs else content[:200]
        
        return overview.strip()
    
    def _extract_core_principles(self, candidate: Dict[str, Any]) -> str:
        """æ ¸å¿ƒåŸå‰‡æŠ½å‡º"""
        
        content = candidate.get("content", "")
        
        # åŸå‰‡ãƒ»ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«é–¢ã™ã‚‹è¨˜è¿°ã‚’æ¤œç´¢
        principles = []
        
        # ç•ªå·ä»˜ããƒªã‚¹ãƒˆã‚’æ¤œç´¢
        numbered_items = re.findall(r'\d+\.\s*\*\*([^*]+)\*\*[^0-9]*', content)
        principles.extend(numbered_items)
        
        # ç®‡æ¡æ›¸ãã‚’æ¤œç´¢
        bullet_items = re.findall(r'-\s*\*\*([^*]+)\*\*', content)
        principles.extend(bullet_items)
        
        if principles:
            formatted_principles = []
            for i, principle in enumerate(principles[:5], 1):
                formatted_principles.append(f"### {i}. **{principle.strip()}**")
            return "\n\n".join(formatted_principles)
        else:
            return "### 1. **å®Ÿè¨¼æ¸ˆã¿æ‰‹æ³•ã®é©ç”¨**\n- æˆåŠŸäº‹ä¾‹ã«åŸºã¥ãç¢ºå®Ÿãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ"
    
    def _extract_implementation_details(self, candidate: Dict[str, Any]) -> str:
        """å®Ÿè£…è©³ç´°æŠ½å‡º"""
        
        content = candidate.get("content", "")
        
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¤œç´¢
        code_blocks = re.findall(r'```(\w+)?\n(.*?)```', content, re.DOTALL)
        
        if code_blocks:
            formatted_code = []
            for lang, code in code_blocks:
                lang = lang or "python"
                formatted_code.append(f"```{lang}\n{code.strip()}\n```")
            return "\n\n".join(formatted_code)
        else:
            # å®Ÿè£…ã«é–¢ã™ã‚‹è¨˜è¿°ã‚’æ¤œç´¢
            impl_patterns = [
                r'å®Ÿè£…[^ã€‚]*ã€‚',
                r'æ‰‹æ³•[^ã€‚]*ã€‚',
                r'ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ[^ã€‚]*ã€‚'
            ]
            
            implementations = []
            for pattern in impl_patterns:
                matches = re.findall(pattern, content)
                implementations.extend(matches)
            
            return "\n".join(implementations) if implementations else "å…·ä½“çš„ãªå®Ÿè£…æ‰‹é †ã¯å…ƒã®KPTåˆ†æã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
    
    def _extract_success_metrics(self, candidate: Dict[str, Any]) -> str:
        """æˆåŠŸæŒ‡æ¨™æŠ½å‡º"""
        
        content = candidate.get("content", "")
        
        # æˆåŠŸæŒ‡æ¨™ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æ¤œç´¢
        metrics = re.findall(r'([0-9]+(?:\.[0-9]+)?[%å€x][^ã€‚]*)', content)
        
        if metrics:
            formatted_metrics = []
            for metric in metrics:
                formatted_metrics.append(f"- {metric}")
            return "\n".join(formatted_metrics)
        else:
            return "- å“è³ªç›®æ¨™ã®é”æˆ\n- ãƒ—ãƒ­ã‚»ã‚¹åŠ¹ç‡ã®æ”¹å–„\n- ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼æº€è¶³åº¦å‘ä¸Š"
    
    def _generate_application_conditions(self, candidate: Dict[str, Any]) -> str:
        """é©ç”¨æ¡ä»¶ç”Ÿæˆ"""
        
        content = candidate.get("content", "")
        
        # å‰ææ¡ä»¶ãƒ»åˆ¶ç´„ã‚’æ¤œç´¢
        conditions = []
        
        condition_patterns = [
            r'å‰æ[^ã€‚]*ã€‚',
            r'æ¡ä»¶[^ã€‚]*ã€‚',
            r'è¦ä»¶[^ã€‚]*ã€‚',
            r'åˆ¶ç´„[^ã€‚]*ã€‚'
        ]
        
        for pattern in condition_patterns:
            matches = re.findall(pattern, content)
            conditions.extend(matches)
        
        if conditions:
            formatted_conditions = []
            for condition in conditions:
                formatted_conditions.append(f"- {condition}")
            return "\n".join(formatted_conditions)
        else:
            return "- é¡ä¼¼ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç’°å¢ƒã§ã®é©ç”¨\n- ååˆ†ãªãƒªã‚½ãƒ¼ã‚¹ãƒ»æ™‚é–“ã®ç¢ºä¿\n- ãƒãƒ¼ãƒ ã®æŠ€è¡“ãƒ¬ãƒ™ãƒ«ãƒ»å­¦ç¿’æ„æ¬²"
    
    def _generate_improvement_section(self, candidate: Dict[str, Any]) -> str:
        """æ”¹å–„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        
        return """### å­¦ç¿’ãƒ«ãƒ¼ãƒ—
- å®Ÿè£… â†’ æ¸¬å®š â†’ åˆ†æ â†’ æ”¹å–„ â†’ æ¬¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé©ç”¨

### ãƒŠãƒ¬ãƒƒã‚¸è“„ç©
- æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¨™æº–åŒ–
- å¤±æ•—äº‹ä¾‹ã®åˆ†æã¨å¯¾ç­–
- æ‰‹æ³•ã®ä»–ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¸ã®é©ç”¨"""
    
    def _generate_conclusion(self, candidate: Dict[str, Any]) -> str:
        """çµè«–ç”Ÿæˆ"""
        
        title = candidate.get("title", "ã“ã®æ‰‹æ³•")
        
        return f"**{title}ã«ã‚ˆã‚Šã€å®Ÿè¨¼æ¸ˆã¿ã®é«˜ã„åŠ¹æœãŒæœŸå¾…ã§ãã¾ã™ã€‚**\n\n### æ ¸å¿ƒçš„ä¾¡å€¤\n1. **åŠ¹ç‡æ€§**: å®Ÿè£…ãƒ»é‹ç”¨åŠ¹ç‡ã®å¤§å¹…å‘ä¸Š\n2. **å“è³ª**: ç¢ºå®Ÿãªå“è³ªç›®æ¨™é”æˆ\n3. **å†ç¾æ€§**: ä»–ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®é©ç”¨å¯èƒ½æ€§\n4. **å­¦ç¿’**: çµ„ç¹”èƒ½åŠ›ã®ç¶™ç¶šçš„å‘ä¸Š\n\nã“ã®æ‰‹æ³•ã¯ã€é¡ä¼¼ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãŠã‘ã‚‹æ–°ã—ã„ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã¨ãªã‚Šã¾ã™ã€‚ ğŸš€"

class KnowledgeValidator:
    """ãƒŠãƒ¬ãƒƒã‚¸å“è³ªæ¤œè¨¼"""
    
    def __init__(self):
        self.quality_criteria = {
            "content_quality": {
                "has_empirical_evidence": 0.25,
                "includes_concrete_examples": 0.25,
                "defines_success_metrics": 0.25,
                "specifies_constraints": 0.25
            },
            "documentation_quality": {
                "follows_standard_format": 0.30,
                "has_searchable_keywords": 0.25,
                "includes_code_examples": 0.25,
                "proper_categorization": 0.20
            },
            "practical_utility": {
                "replication_feasibility": 0.40,
                "clear_implementation_steps": 0.30,
                "troubleshooting_info": 0.30
            },
            "maintainability": {
                "version_info": 0.25,
                "update_schedule": 0.25,
                "related_documents": 0.25,
                "review_history": 0.25
            }
        }
    
    def validate_knowledge_document(self, file_path: str) -> Dict[str, Any]:
        """ãƒŠãƒ¬ãƒƒã‚¸æ–‡æ›¸æ¤œè¨¼"""
        
        if not os.path.exists(file_path):
            return {"error": "File not found", "file_path": file_path}
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        validation_results = {}
        overall_score = 0.0
        
        for dimension, criteria in self.quality_criteria.items():
            dimension_score = 0.0
            dimension_details = {}
            
            for criterion, weight in criteria.items():
                score = self._evaluate_criterion(content, criterion)
                dimension_details[criterion] = score
                dimension_score += score * weight
            
            validation_results[dimension] = {
                "score": dimension_score,
                "details": dimension_details
            }
            overall_score += dimension_score
        
        overall_score /= len(self.quality_criteria)
        
        return {
            "file_path": file_path,
            "overall_quality_score": overall_score,
            "validation_results": validation_results,
            "approval_status": "approved" if overall_score >= 0.8 else "revision_required",
            "recommendations": self._generate_recommendations(validation_results)
        }
    
    def _evaluate_criterion(self, content: str, criterion: str) -> float:
        """åŸºæº–è©•ä¾¡"""
        
        evaluation_map = {
            "has_empirical_evidence": lambda c: 1.0 if re.search(r'å®Ÿè¨¼|å®Ÿç¸¾|ãƒ‡ãƒ¼ã‚¿|çµæœ|æˆæœ', c) else 0.0,
            "includes_concrete_examples": lambda c: 1.0 if re.search(r'```|ä¾‹:|å®Ÿè£…|ã‚³ãƒ¼ãƒ‰', c) else 0.0,
            "defines_success_metrics": lambda c: 1.0 if re.search(r'æŒ‡æ¨™|ãƒ¡ãƒˆãƒªã‚¯ã‚¹|æ¸¬å®š|[0-9]+%', c) else 0.0,
            "specifies_constraints": lambda c: 1.0 if re.search(r'å‰æ|æ¡ä»¶|åˆ¶ç´„|è¦ä»¶', c) else 0.0,
            "follows_standard_format": lambda c: 1.0 if re.search(r'# ğŸ¯.*\*\*æŠ½å‡ºå…ƒ\*\*.*## ğŸ“‹ æ¦‚è¦', c, re.DOTALL) else 0.0,
            "has_searchable_keywords": lambda c: 1.0 if re.search(r'ğŸ¯|ğŸ“‹|ğŸ”§|ğŸ“Š', c) else 0.0,
            "includes_code_examples": lambda c: min(1.0, len(re.findall(r'```', c)) / 4),
            "proper_categorization": lambda c: 1.0 if re.search(r'technical_|development_|business_|project_|lessons_', c) else 0.0,
            "replication_feasibility": lambda c: 1.0 if re.search(r'æ‰‹é †|ã‚¹ãƒ†ãƒƒãƒ—|å®Ÿè£…|æ–¹æ³•', c) else 0.0,
            "clear_implementation_steps": lambda c: min(1.0, len(re.findall(r'\d+\.|###|\*\*æ‰‹é †', c)) / 5),
            "troubleshooting_info": lambda c: 1.0 if re.search(r'æ³¨æ„|å•é¡Œ|ã‚¨ãƒ©ãƒ¼|å¯¾å¿œ', c) else 0.0,
            "version_info": lambda c: 1.0 if re.search(r'\d{4}-\d{2}-\d{2}|\d{4}å¹´\d{1,2}æœˆ', c) else 0.0,
            "update_schedule": lambda c: 1.0 if re.search(r'æ›´æ–°|è¦‹ç›´ã—|ãƒ¬ãƒ“ãƒ¥ãƒ¼', c) else 0.0,
            "related_documents": lambda c: 1.0 if re.search(r'é–¢é€£|å‚ç…§|å‚è€ƒ', c) else 0.0,
            "review_history": lambda c: 1.0 if re.search(r'å±¥æ­´|ãƒãƒ¼ã‚¸ãƒ§ãƒ³|å¤‰æ›´', c) else 0.0
        }
        
        evaluator = evaluation_map.get(criterion, lambda c: 0.5)
        return evaluator(content)
    
    def _generate_recommendations(self, validation_results: Dict[str, Any]) -> List[str]:
        """æ”¹å–„æ¨å¥¨ç”Ÿæˆ"""
        
        recommendations = []
        
        for dimension, results in validation_results.items():
            if results["score"] < 0.7:
                low_criteria = [
                    criterion for criterion, score in results["details"].items()
                    if score < 0.5
                ]
                
                if low_criteria:
                    recommendations.append(f"{dimension}ã®æ”¹å–„ãŒå¿…è¦: {', '.join(low_criteria)}")
        
        return recommendations

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    
    parser = argparse.ArgumentParser(description="KPTåˆ†æãƒŠãƒ¬ãƒƒã‚¸æŠ½å‡ºãƒ»ç®¡ç†ãƒ„ãƒ¼ãƒ«")
    subparsers = parser.add_subparsers(dest="command", help="åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰")
    
    # pre-check ã‚³ãƒãƒ³ãƒ‰ (æ–°è¦è¿½åŠ )
    precheck_parser = subparsers.add_parser("pre-check", help="ã‚¿ã‚¹ã‚¯ç€æ‰‹å‰ãƒŠãƒ¬ãƒƒã‚¸ç¢ºèª")
    precheck_parser.add_argument("--task", required=True, help="ã‚¿ã‚¹ã‚¯èª¬æ˜")
    precheck_parser.add_argument("--knowledge-dir", default="knowledge/", help="ãƒŠãƒ¬ãƒƒã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    precheck_parser.add_argument("--output-guidance", help="ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«")

    # extract ã‚³ãƒãƒ³ãƒ‰
    extract_parser = subparsers.add_parser("extract", help="KPTåˆ†æã‹ã‚‰ãƒŠãƒ¬ãƒƒã‚¸æŠ½å‡º")
    extract_parser.add_argument("--kpt-file", required=True, help="KPTåˆ†æãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    extract_parser.add_argument("--output-dir", default="knowledge/", help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    extract_parser.add_argument("--auto-generate", action="store_true", help="è‡ªå‹•æ–‡æ›¸ç”Ÿæˆ")
    
    # validate ã‚³ãƒãƒ³ãƒ‰
    validate_parser = subparsers.add_parser("validate", help="ãƒŠãƒ¬ãƒƒã‚¸æ–‡æ›¸æ¤œè¨¼")
    validate_parser.add_argument("--knowledge-dir", default="knowledge/", help="ãƒŠãƒ¬ãƒƒã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    validate_parser.add_argument("--knowledge-file", help="ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼")
    
    # review ã‚³ãƒãƒ³ãƒ‰
    review_parser = subparsers.add_parser("review", help="ãƒŠãƒ¬ãƒƒã‚¸å“è³ªãƒ¬ãƒ“ãƒ¥ãƒ¼")
    review_parser.add_argument("--knowledge-file", required=True, help="ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«")
    review_parser.add_argument("--output-report", help="ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›å…ˆ")
    
    args = parser.parse_args()
    
    if args.command == "pre-check":
        pre_check_knowledge(args)
    elif args.command == "extract":
        extract_knowledge(args)
    elif args.command == "validate":
        validate_knowledge(args)
    elif args.command == "review":
        review_knowledge(args)
    else:
        parser.print_help()

def pre_check_knowledge(args):
    """ã‚¿ã‚¹ã‚¯ç€æ‰‹å‰ãƒŠãƒ¬ãƒƒã‚¸ç¢ºèªå®Ÿè¡Œ"""
    
    print(f"ğŸ” ã‚¿ã‚¹ã‚¯ç€æ‰‹å‰ãƒŠãƒ¬ãƒƒã‚¸ç¢ºèª: {args.task}")
    
    # Step 0: ãƒ–ãƒ©ãƒ³ãƒæˆ¦ç•¥ç¢ºèª (æœ€å„ªå…ˆ)
    try:
        branch_check_result = check_branch_strategy(args.task)
        print(f"ğŸŒ¿ ãƒ–ãƒ©ãƒ³ãƒæˆ¦ç•¥ç¢ºèª: {branch_check_result['status']}")
        
        if branch_check_result['action_required']:
            print(f"âš ï¸ ãƒ–ãƒ©ãƒ³ãƒã‚¢ã‚¯ã‚·ãƒ§ãƒ³å¿…è¦: {branch_check_result['recommendation']}")
            print("ğŸ“‹ é©åˆ‡ãªãƒ–ãƒ©ãƒ³ãƒã«åˆ‡ã‚Šæ›¿ãˆå¾Œã€å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
    except Exception as e:
        print(f"âš ï¸ ãƒ–ãƒ©ãƒ³ãƒæˆ¦ç•¥ç¢ºèªã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        print("ğŸ“‹ æ‰‹å‹•ã§ãƒ–ãƒ©ãƒ³ãƒã‚’ç¢ºèªã—ã¦ã‹ã‚‰ç¶šè¡Œã—ã¦ãã ã•ã„")
    
    # ãƒŠãƒ¬ãƒƒã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨ç¢ºèª
    knowledge_dir = Path(args.knowledge_dir)
    if not knowledge_dir.exists():
        print(f"âš ï¸ ãƒŠãƒ¬ãƒƒã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {knowledge_dir}")
        print("ğŸ“‹ æ–°è¦ã‚¿ã‚¹ã‚¯ã¨ã—ã¦é€²è¡Œã—ã¾ã™")
        return
    
    # é–¢é€£ãƒŠãƒ¬ãƒƒã‚¸ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
    md_files = list(knowledge_dir.rglob("*.md"))
    
    if not md_files:
        print(f"ğŸ“‹ ãƒŠãƒ¬ãƒƒã‚¸ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ–°è¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã—ã¦æ…é‡ã«é€²è¡Œã—ã¦ãã ã•ã„ã€‚")
        return
    
    print(f"ğŸ“š {len(md_files)}å€‹ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ä¸­...")
    
    # ã‚¿ã‚¹ã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    task_keywords = extract_task_keywords(args.task)
    print(f"ğŸ” æ¤œå‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(task_keywords)}")
    
    # é–¢é€£ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢
    relevant_knowledge = []
    
    for md_file in md_files:
        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
            relevance_score = calculate_relevance_score(content, task_keywords)
            
            if relevance_score > 0.2:  # 20%ä»¥ä¸Šã®é–¢é€£æ€§
                relevant_knowledge.append({
                    "file": md_file,
                    "relevance": relevance_score,
                    "category": md_file.parent.name,
                    "matching_keywords": find_matching_keywords(content, task_keywords)
                })
                
        except Exception as e:
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {md_file} - {e}")
    
    # é–¢é€£åº¦é †ã«ã‚½ãƒ¼ãƒˆ
    relevant_knowledge.sort(key=lambda x: x["relevance"], reverse=True)
    
    if relevant_knowledge:
        print(f"\nğŸ“‹ é–¢é€£ãƒŠãƒ¬ãƒƒã‚¸ç™ºè¦‹: {len(relevant_knowledge)}ä»¶")
        print("=" * 50)
        
        for i, knowledge in enumerate(relevant_knowledge[:5], 1):  # ä¸Šä½5ä»¶è¡¨ç¤º
            print(f"{i}. {knowledge['file'].name}")
            print(f"   ã‚«ãƒ†ã‚´ãƒª: {knowledge['category']}")
            print(f"   é–¢é€£åº¦: {knowledge['relevance']:.2f}")
            print(f"   ãƒãƒƒãƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(knowledge['matching_keywords'])}")
            print()
        
        # ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ç”Ÿæˆ
        guidance = generate_task_guidance(args.task, relevant_knowledge)
        
        if args.output_guidance:
            with open(args.output_guidance, 'w', encoding='utf-8') as f:
                f.write(guidance)
            print(f"ğŸ“„ ã‚¿ã‚¹ã‚¯ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹å‡ºåŠ›: {args.output_guidance}")
        else:
            print("ğŸ“‹ ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã‚¬ã‚¤ãƒ€ãƒ³ã‚¹:")
            print(guidance)
    
    else:
        print("ğŸ“‹ ç›´æ¥é–¢é€£ã™ã‚‹ãƒŠãƒ¬ãƒƒã‚¸ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        print("ğŸ’¡ æ–°è¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æ…é‡ãªè¨­è¨ˆãƒ»å®Ÿè£…ã‚’æ¨å¥¨ã—ã¾ã™")
        
        # ä¸€èˆ¬çš„ãªã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ç”Ÿæˆ
        general_guidance = generate_general_guidance(args.task)
        print("\nğŸ“‹ ä¸€èˆ¬çš„ãªã‚¬ã‚¤ãƒ€ãƒ³ã‚¹:")
        print(general_guidance)

def extract_task_keywords(task_description: str) -> List[str]:
    """ã‚¿ã‚¹ã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º"""
    
    # æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    technical_keywords = [
        "å®Ÿè£…", "è¨­è¨ˆ", "çµ±åˆ", "ãƒ†ã‚¹ãƒˆ", "ãƒ‡ãƒ—ãƒ­ã‚¤", "æœ€é©åŒ–",
        "ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£", "API", "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
        "RAG", "æ—¥æœ¬èª", "PLaMo", "Embedding", "ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿", "æ¤œç´¢"
    ]
    
    # ãƒ“ã‚¸ãƒã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰  
    business_keywords = [
        "æˆ¦ç•¥", "è¨ˆç”»", "åˆ†æ", "æ”¹å–„", "åŠ¹ç‡åŒ–", "å“è³ª",
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼", "å¸‚å ´", "ç«¶åˆ", "ROI", "å·®åˆ¥åŒ–", "ä¾¡å€¤"
    ]
    
    # ãƒ—ãƒ­ã‚»ã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    process_keywords = [
        "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ", "ç®¡ç†", "ãƒ¬ãƒ“ãƒ¥ãƒ¼", "æ‰¿èª", "ãƒªãƒªãƒ¼ã‚¹",
        "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ", "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³", "å”åŠ›", "Phase"
    ]
    
    # ãƒ–ãƒ©ãƒ³ãƒæˆ¦ç•¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    branch_keywords = [
        "ãƒ–ãƒ©ãƒ³ãƒ", "ãƒãƒ¼ã‚¸", "çµ±åˆ", "feature", "main", "åˆ‡ã‚Šæ›¿ãˆ",
        "Phase", "å®Ÿè£…", "é–‹ç™º", "ãƒªãƒªãƒ¼ã‚¹"
    ]
    
    all_keywords = technical_keywords + business_keywords + process_keywords + branch_keywords
    
    # ã‚¿ã‚¹ã‚¯è¨˜è¿°å†…ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º
    detected_keywords = []
    task_lower = task_description.lower()
    
    for keyword in all_keywords:
        if keyword.lower() in task_lower:
            detected_keywords.append(keyword)
    
    return detected_keywords

def calculate_relevance_score(content: str, task_keywords: List[str]) -> float:
    """é–¢é€£åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—"""
    
    if not task_keywords:
        return 0.0
    
    content_lower = content.lower()
    matches = 0
    
    for keyword in task_keywords:
        if keyword.lower() in content_lower:
            matches += 1
    
    return matches / len(task_keywords)

def find_matching_keywords(content: str, task_keywords: List[str]) -> List[str]:
    """ãƒãƒƒãƒãƒ³ã‚°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢"""
    
    content_lower = content.lower()
    matching = []
    
    for keyword in task_keywords:
        if keyword.lower() in content_lower:
            matching.append(keyword)
    
    return matching

def generate_task_guidance(task_description: str, relevant_knowledge: List[Dict[str, Any]]) -> str:
    """ã‚¿ã‚¹ã‚¯ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ç”Ÿæˆ"""
    
    guidance = f"""# ğŸ¯ ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã‚¬ã‚¤ãƒ€ãƒ³ã‚¹

**ã‚¿ã‚¹ã‚¯**: {task_description}

## ğŸ“š é–¢é€£ãƒŠãƒ¬ãƒƒã‚¸ (ä¸Šä½5ä»¶)

"""
    
    for i, knowledge in enumerate(relevant_knowledge[:5], 1):
        guidance += f"### {i}. {knowledge['file'].name}\n"
        guidance += f"- **ã‚«ãƒ†ã‚´ãƒª**: {knowledge['category']}\n"
        guidance += f"- **é–¢é€£åº¦**: {knowledge['relevance']:.2f}\n"
        guidance += f"- **ãƒãƒƒãƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {', '.join(knowledge['matching_keywords'])}\n"
        guidance += f"- **ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: `{knowledge['file']}`\n\n"
    
    guidance += """## âœ… å®Ÿè¡Œå‰ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

â–¡ ä¸Šè¨˜é–¢é€£ãƒŠãƒ¬ãƒƒã‚¸ã®è©³ç´°ç¢ºèªå®Œäº†
â–¡ é©ç”¨å¯èƒ½ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å®šå®Œäº†
â–¡ æ—¢çŸ¥ãƒªã‚¹ã‚¯è¦å› ã®ç¢ºèªå®Œäº†
â–¡ å“è³ªåŸºæº–ãƒ»æˆåŠŸæŒ‡æ¨™ã®è¨­å®šå®Œäº†
â–¡ å®Ÿè£…æ–¹é‡ãƒ»ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ±ºå®šå®Œäº†

## ğŸ” æ¨å¥¨ç¢ºèªäº‹é …

1. **æŠ€è¡“ãƒ‘ã‚¿ãƒ¼ãƒ³**: é¡ä¼¼å®Ÿè£…ã®è¨­è¨ˆãƒ»ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç¢ºèª
2. **æˆåŠŸè¦å› **: éå»ã®æˆåŠŸäº‹ä¾‹ã‹ã‚‰é©ç”¨å¯èƒ½ãªè¦å› ã‚’æŠ½å‡º
3. **ãƒªã‚¹ã‚¯å¯¾ç­–**: æ—¢çŸ¥ã®å•é¡Œãƒ»å¤±æ•—äº‹ä¾‹ã‹ã‚‰äºˆé˜²ç­–ã‚’æº–å‚™
4. **å“è³ªåŸºæº–**: æœŸå¾…ã•ã‚Œã‚‹å“è³ªãƒ¬ãƒ™ãƒ«ãƒ»æ¸¬å®šæ–¹æ³•ã‚’æ˜ç¢ºåŒ–

## ğŸš€ æ¬¡ã‚¹ãƒ†ãƒƒãƒ—

é–¢é€£ãƒŠãƒ¬ãƒƒã‚¸ã®è©³ç´°ç¢ºèªå¾Œã€å®Ÿè£…ã«ç€æ‰‹ã—ã¦ãã ã•ã„ã€‚
ä¸æ˜ç‚¹ãŒã‚ã‚Œã°ã€éå»ã®æˆåŠŸäº‹ä¾‹ãƒ»KPTåˆ†æã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
"""
    
    return guidance

def generate_general_guidance(task_description: str) -> str:
    """ä¸€èˆ¬çš„ãªã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ç”Ÿæˆ"""
    
    return f"""# ğŸ¯ æ–°è¦ã‚¿ã‚¹ã‚¯ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹

**ã‚¿ã‚¹ã‚¯**: {task_description}

## ğŸ“‹ æ–°è¦ãƒ‘ã‚¿ãƒ¼ãƒ³å®Ÿè¡ŒæŒ‡é‡

### âœ… åŸºæœ¬ãƒã‚§ãƒƒã‚¯é …ç›®
â–¡ è¦ä»¶ãƒ»ç›®æ¨™ã®æ˜ç¢ºåŒ–
â–¡ æŠ€è¡“çš„å®Ÿç¾å¯èƒ½æ€§ã®æ¤œè¨¼
â–¡ ãƒªã‚¹ã‚¯è¦å› ã®äº‹å‰ç‰¹å®š
â–¡ æˆåŠŸæŒ‡æ¨™ãƒ»æ¸¬å®šæ–¹æ³•ã®è¨­å®š
â–¡ å®Ÿè£…ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ¤œè¨

### ğŸ” æ¨å¥¨åˆ†æäº‹é …
1. **æŠ€è¡“èª¿æŸ»**: é–¢é€£æŠ€è¡“ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª¿æŸ»
2. **è¨­è¨ˆæ¤œè¨**: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ»ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹è¨­è¨ˆ
3. **å“è³ªè¨ˆç”»**: ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ãƒ»å“è³ªä¿è¨¼æ‰‹æ³•
4. **ãƒªã‚¹ã‚¯ç®¡ç†**: æ½œåœ¨çš„å•é¡Œãƒ»è»½æ¸›ç­–ã®æº–å‚™

### ğŸ“š å‚è€ƒæ¨å¥¨
- é¡ä¼¼ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®äº‹ä¾‹èª¿æŸ»
- æ¥­ç•Œãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã®ç¢ºèª
- æŠ€è¡“æ–‡æ›¸ãƒ»å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç²¾èª­

### ğŸ¯ å®Ÿè£…æ–¹é‡
æ–°è¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãŸã‚ã€æ…é‡ã‹ã¤æ®µéšçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¨å¥¨ã—ã¾ã™ã€‚
å°è¦æ¨¡ãªãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‹ã‚‰é–‹å§‹ã—ã€æ®µéšçš„ã«æ©Ÿèƒ½ã‚’æ‹¡å¼µã—ã¦ãã ã•ã„ã€‚
"""

def extract_knowledge(args):
    """ãƒŠãƒ¬ãƒƒã‚¸æŠ½å‡ºå®Ÿè¡Œ"""
    
    print(f"ğŸ” KPTåˆ†æãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æä¸­: {args.kpt_file}")
    
    # KPTåˆ†æãƒ•ã‚¡ã‚¤ãƒ«è§£æ
    analyzer = KPTAnalyzer()
    analysis_result = analyzer.parse_kpt_file(args.kpt_file)
    
    # ãƒŠãƒ¬ãƒƒã‚¸å€™è£œæŠ½å‡º
    candidates = analyzer.extract_knowledge_candidates(analysis_result)
    
    print(f"ğŸ“‹ {len(candidates)}å€‹ã®ãƒŠãƒ¬ãƒƒã‚¸å€™è£œã‚’æŠ½å‡º")
    
    # å€™è£œä¸€è¦§è¡¨ç¤º
    for i, candidate in enumerate(candidates, 1):
        print(f"{i}. {candidate['title']} ({candidate['suggested_category']}) - {candidate['security_level']}")
    
    if args.auto_generate:
        # è‡ªå‹•æ–‡æ›¸ç”Ÿæˆ
        generator = KnowledgeDocumentGenerator()
        
        for candidate in candidates:
            if candidate['security_level'] in ['internal', 'confidential']:
                # ãƒŠãƒ¬ãƒƒã‚¸æ–‡æ›¸ç”Ÿæˆ
                document_content = generator.generate_knowledge_document(candidate, analysis_result)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                category = candidate['suggested_category']
                title_safe = re.sub(r'[^\w\-_]', '_', candidate['title'])
                file_name = f"{title_safe}.md"
                
                output_path = Path(args.output_dir) / category / file_name
                output_path.parent.mkdir(parents=True, exist_ok=True)
                
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(document_content)
                
                print(f"âœ… ãƒŠãƒ¬ãƒƒã‚¸æ–‡æ›¸ç”Ÿæˆ: {output_path}")
    
    print("ğŸ¯ ãƒŠãƒ¬ãƒƒã‚¸æŠ½å‡ºå®Œäº†")

def validate_knowledge(args):
    """ãƒŠãƒ¬ãƒƒã‚¸æ¤œè¨¼å®Ÿè¡Œ"""
    
    validator = KnowledgeValidator()
    
    if args.knowledge_file:
        # ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        result = validator.validate_knowledge_document(args.knowledge_file)
        print(f"ğŸ“‹ æ¤œè¨¼çµæœ: {args.knowledge_file}")
        print(f"ç·åˆå“è³ªã‚¹ã‚³ã‚¢: {result['overall_quality_score']:.2f}")
        print(f"æ‰¿èªçŠ¶æ³: {result['approval_status']}")
        
        if result['recommendations']:
            print("æ¨å¥¨æ”¹å–„ç‚¹:")
            for rec in result['recommendations']:
                print(f"  - {rec}")
    
    else:
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå…¨ä½“æ¤œè¨¼
        knowledge_dir = Path(args.knowledge_dir)
        
        if not knowledge_dir.exists():
            print(f"âŒ ãƒŠãƒ¬ãƒƒã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {knowledge_dir}")
            return
        
        md_files = list(knowledge_dir.rglob("*.md"))
        
        print(f"ğŸ” {len(md_files)}å€‹ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œè¨¼ä¸­")
        
        total_score = 0.0
        approved_count = 0
        
        for md_file in md_files:
            result = validator.validate_knowledge_document(str(md_file))
            
            if 'error' not in result:
                total_score += result['overall_quality_score']
                if result['approval_status'] == 'approved':
                    approved_count += 1
                
                print(f"  {md_file.name}: {result['overall_quality_score']:.2f} ({result['approval_status']})")
        
        if md_files:
            avg_score = total_score / len(md_files)
            approval_rate = approved_count / len(md_files) * 100
            
            print(f"\nğŸ“Š æ¤œè¨¼ã‚µãƒãƒªãƒ¼:")
            print(f"  å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {avg_score:.2f}")
            print(f"  æ‰¿èªç‡: {approval_rate:.1f}%")

def review_knowledge(args):
    """ãƒŠãƒ¬ãƒƒã‚¸ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œ"""
    
    validator = KnowledgeValidator()
    result = validator.validate_knowledge_document(args.knowledge_file)
    
    print(f"ğŸ“‹ è©³ç´°ãƒ¬ãƒ“ãƒ¥ãƒ¼: {args.knowledge_file}")
    print("=" * 50)
    
    if 'error' in result:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
        return
    
    print(f"ç·åˆå“è³ªã‚¹ã‚³ã‚¢: {result['overall_quality_score']:.2f}")
    print(f"æ‰¿èªçŠ¶æ³: {result['approval_status']}")
    print()
    
    for dimension, dim_result in result['validation_results'].items():
        print(f"## {dimension}")
        print(f"ã‚¹ã‚³ã‚¢: {dim_result['score']:.2f}")
        
        for criterion, score in dim_result['details'].items():
            status = "âœ…" if score > 0.7 else "âš ï¸" if score > 0.3 else "âŒ"
            print(f"  {status} {criterion}: {score:.2f}")
        print()
    
    if result['recommendations']:
        print("## æ”¹å–„æ¨å¥¨")
        for rec in result['recommendations']:
            print(f"  ğŸ”§ {rec}")
    
    # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
    if args.output_report:
        with open(args.output_report, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›: {args.output_report}")

def check_branch_strategy(task_description: str) -> Dict[str, Any]:
    """ãƒ–ãƒ©ãƒ³ãƒæˆ¦ç•¥ç¢ºèª"""
    
    try:
        import subprocess
        
        # ç¾åœ¨ã®ãƒ–ãƒ©ãƒ³ãƒåã‚’å–å¾—
        result = subprocess.run(['git', 'branch', '--show-current'], 
                              capture_output=True, text=True, check=True)
        current_branch = result.stdout.strip()
        
        # æ¨å¥¨ãƒ–ãƒ©ãƒ³ãƒã‚’æ±ºå®š
        recommended_branch = determine_appropriate_branch(task_description)
        
        # ãƒ–ãƒ©ãƒ³ãƒãŒé©åˆ‡ã‹ãƒã‚§ãƒƒã‚¯
        is_appropriate = is_branch_appropriate(current_branch, task_description)
        
        branch_check_result = {
            'current_branch': current_branch,
            'recommended_branch': recommended_branch,
            'is_appropriate': is_appropriate,
            'action_required': not is_appropriate,
            'status': 'OK' if is_appropriate else 'ãƒ–ãƒ©ãƒ³ãƒåˆ‡ã‚Šæ›¿ãˆæ¨å¥¨',
            'recommendation': f"æ¨å¥¨ãƒ–ãƒ©ãƒ³ãƒ: {recommended_branch}" if not is_appropriate else f"ç¾åœ¨ã®ãƒ–ãƒ©ãƒ³ãƒ({current_branch})ã¯é©åˆ‡ã§ã™"
        }
        
        return branch_check_result
        
    except subprocess.CalledProcessError:
        return {
            'current_branch': 'unknown',
            'recommended_branch': 'unknown',
            'is_appropriate': True,  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç¶šè¡Œã‚’è¨±å¯
            'action_required': False,
            'status': 'gitã‚³ãƒãƒ³ãƒ‰ã‚¨ãƒ©ãƒ¼',
            'recommendation': 'æ‰‹å‹•ã§ãƒ–ãƒ©ãƒ³ãƒã‚’ç¢ºèªã—ã¦ãã ã•ã„'
        }
    except Exception as e:
        return {
            'current_branch': 'error',
            'recommended_branch': 'error',
            'is_appropriate': True,  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç¶šè¡Œã‚’è¨±å¯
            'action_required': False,
            'status': f'ã‚¨ãƒ©ãƒ¼: {e}',
            'recommendation': 'æ‰‹å‹•ã§ãƒ–ãƒ©ãƒ³ãƒã‚’ç¢ºèªã—ã¦ãã ã•ã„'
        }

def determine_appropriate_branch(task_description: str) -> str:
    """ã‚¿ã‚¹ã‚¯ã«å¿œã˜ãŸé©åˆ‡ãªãƒ–ãƒ©ãƒ³ãƒã‚’æ±ºå®š"""
    
    task_lower = task_description.lower()
    
    # ã‚¿ã‚¹ã‚¯å†…å®¹ã«åŸºã¥ããƒ–ãƒ©ãƒ³ãƒãƒãƒƒãƒ”ãƒ³ã‚°
    branch_mapping = {
        'phase 3': 'feature/rag-phase3-plamo-integration',
        'phase3': 'feature/rag-phase3-plamo-integration',
        'plamo': 'feature/rag-phase3-plamo-integration',
        'embedding': 'feature/rag-phase3-plamo-integration',
        'vector': 'feature/rag-phase3-plamo-integration',
        'phase 2': 'feature/rag-phase2-advanced-metadata',
        'phase2': 'feature/rag-phase2-advanced-metadata',
        'metadata': 'feature/rag-phase2-advanced-metadata',
        'phase 1': 'feature/rag-phase1-basic-implementation',
        'phase1': 'feature/rag-phase1-basic-implementation',
        'rag': 'feature/rag-phase1-basic-implementation',
        'hotfix': 'hotfix/',
        'bugfix': 'bugfix/',
        'docs': 'feature/documentation',
        'ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ': 'feature/documentation',
        'ãƒ†ã‚¹ãƒˆ': 'feature/testing',
        'test': 'feature/testing'
    }
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
    for keyword, branch in branch_mapping.items():
        if keyword in task_lower:
            return branch
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯main
    return 'main'

def is_branch_appropriate(current_branch: str, task_description: str) -> bool:
    """ç¾åœ¨ã®ãƒ–ãƒ©ãƒ³ãƒãŒã‚¿ã‚¹ã‚¯ã«é©åˆ‡ã‹ãƒã‚§ãƒƒã‚¯"""
    
    recommended_branch = determine_appropriate_branch(task_description)
    
    # å®Œå…¨ä¸€è‡´
    if current_branch == recommended_branch:
        return True
    
    # mainãƒ–ãƒ©ãƒ³ãƒã¯æ±ç”¨çš„ãªã‚¿ã‚¹ã‚¯ã«ã¯é©åˆ‡
    if current_branch == 'main' and recommended_branch == 'main':
        return True
    
    # feature/ãƒ–ãƒ©ãƒ³ãƒã®éƒ¨åˆ†ä¸€è‡´ãƒã‚§ãƒƒã‚¯
    if current_branch.startswith('feature/') and recommended_branch.startswith('feature/'):
        # åŒä¸€ãƒ•ã‚§ãƒ¼ã‚ºã®ãƒ–ãƒ©ãƒ³ãƒãªã‚‰é©åˆ‡ã¨ã™ã‚‹
        if 'phase1' in current_branch and 'phase1' in recommended_branch:
            return True
        if 'phase2' in current_branch and 'phase2' in recommended_branch:
            return True
        if 'phase3' in current_branch and 'phase3' in recommended_branch:
            return True
    
    return False

if __name__ == "__main__":
    main()