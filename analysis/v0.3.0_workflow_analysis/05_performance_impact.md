# âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å½±éŸ¿åˆ†æ

**å¯¾è±¡**: ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ»é‹ç”¨æ‹…å½“è€…ãƒ»æŠ€è¡“ãƒªãƒ¼ãƒ€ãƒ¼  
**ç›®çš„**: v0.3.0ã«ã‚ˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å¤‰åŒ–ã®è©³ç´°åˆ†æã¨æœ€é©åŒ–æŒ‡é‡

---

## ğŸ“Š **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å¤‰åŒ–æ¦‚è¦**

### **åŸºæœ¬æ€§èƒ½æ¯”è¼ƒ**

| ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º | v0.1.0 | v0.3.0 (RAGç„¡åŠ¹) | v0.3.0 (RAGæœ‰åŠ¹) | å½±éŸ¿åº¦ |
|--------------|--------|------------------|------------------|--------|
| **100è¡Œ** | 5ms | 5ms | 50ms | +1000% |
| **1,000è¡Œ** | 25ms | 25ms | 200ms | +800% |
| **10,000è¡Œ** | 150ms | 150ms | 2s | +1333% |
| **100,000è¡Œ** | 1.5s | 1.5s | 20s | +1333% |

### **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¯”è¼ƒ**

| å‡¦ç†æ®µéš | v0.1.0 | v0.3.0 (RAGç„¡åŠ¹) | v0.3.0 (RAGæœ‰åŠ¹) |
|----------|--------|------------------|------------------|
| **ãƒ™ãƒ¼ã‚¹å‡¦ç†** | 10MB | 10MB | 10MB |
| **JSONãƒ­ãƒ¼ãƒ‰** | +5MB | +5MB | +5MB |
| **ãƒ†ãƒ¼ãƒ–ãƒ«å¤‰æ›** | +15MB | +15MB | +15MB |
| **RAG Phase 1** | - | - | +30MB |
| **RAG Phase 2** | - | - | +50MB |
| **RAG Phase 3** | - | - | +150MB |
| **åˆè¨ˆ** | **30MB** | **30MB** | **260MB** |

---

## ğŸ”„ **å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—åˆ¥è©³ç´°åˆ†æ**

### **Phase 1: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯å‡¦ç†**

#### **MetadataExtractor ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**
```python
# å®Ÿæ¸¬å€¤ï¼ˆ10,000è¡Œãƒ‡ãƒ¼ã‚¿ï¼‰
Performance Profile - MetadataExtractor:
â”œâ”€â”€ JSON Schemaç”Ÿæˆ: 50ms
â”œâ”€â”€ ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒãƒƒãƒ”ãƒ³ã‚°: 150ms
â”œâ”€â”€ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º: 100ms
â”œâ”€â”€ çµ±è¨ˆæƒ…å ±è¨ˆç®—: 200ms
â””â”€â”€ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: 100ms
Total: 600ms
```

#### **SemanticChunker ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**
```python
# ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥åˆ¥å‡¦ç†æ™‚é–“ï¼ˆ10,000è¡Œï¼‰
Chunking Strategy Performance:
â”œâ”€â”€ adaptive: 800ms (é«˜ç²¾åº¦ãƒ»ä¸­é€Ÿåº¦)
â”œâ”€â”€ fixed-size: 300ms (ä¸­ç²¾åº¦ãƒ»é«˜é€Ÿåº¦)
â”œâ”€â”€ japanese-adaptive: 1200ms (æœ€é«˜ç²¾åº¦ãƒ»ä½é€Ÿåº¦)
â””â”€â”€ semantic-boundary: 1000ms (é«˜ç²¾åº¦ãƒ»ä¸­é€Ÿåº¦)
```

### **Phase 2: é«˜åº¦ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ**

#### **AdvancedMetadataGenerator ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**
```python
# æ©Ÿèƒ½åˆ¥å‡¦ç†æ™‚é–“ï¼ˆ10,000è¡Œãƒ‡ãƒ¼ã‚¿ï¼‰
Advanced Processing Breakdown:
â”œâ”€â”€ çµ±è¨ˆåˆ†æ: 500ms
â”‚   â”œâ”€â”€ æ•°å€¤çµ±è¨ˆ: 200ms
â”‚   â”œâ”€â”€ ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆ: 150ms
â”‚   â””â”€â”€ åˆ†å¸ƒè§£æ: 150ms
â”œâ”€â”€ ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£èªè­˜: 800ms
â”‚   â”œâ”€â”€ æ—¥æœ¬èªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ: 400ms
â”‚   â”œâ”€â”€ ãƒ“ã‚¸ãƒã‚¹ç”¨èªæ¤œå‡º: 250ms
â”‚   â””â”€â”€ ä¿¡é ¼åº¦è¨ˆç®—: 150ms
â”œâ”€â”€ ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡: 300ms
â””â”€â”€ PLaMoç‰¹å¾´é‡æº–å‚™: 400ms
Total: 2000ms
```

#### **SearchFacetGenerator ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**
```python
# ãƒ•ã‚¡ã‚»ãƒƒãƒˆç”Ÿæˆå‡¦ç†æ™‚é–“
Facet Generation Performance:
â”œâ”€â”€ ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ•ã‚¡ã‚»ãƒƒãƒˆ: 200ms
â”œâ”€â”€ æ•°å€¤ç¯„å›²ãƒ•ã‚¡ã‚»ãƒƒãƒˆ: 150ms
â”œâ”€â”€ æ™‚ç³»åˆ—ãƒ•ã‚¡ã‚»ãƒƒãƒˆ: 100ms
â”œâ”€â”€ ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ•ã‚¡ã‚»ãƒƒãƒˆ: 250ms
â””â”€â”€ UIæœ€é©åŒ–è¨­å®š: 100ms
Total: 800ms
```

### **Phase 3: PLaMoçµ±åˆ**

#### **VectorProcessor ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**
```python
# PLaMoãƒ™ã‚¯ãƒˆãƒ«å‡¦ç†ï¼ˆ1,000ãƒãƒ£ãƒ³ã‚¯ï¼‰
Vector Processing Profile:
â”œâ”€â”€ ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†: 500ms
â”œâ”€â”€ PLaMoåŸ‹ã‚è¾¼ã¿ç”Ÿæˆ: 15000ms (15s)
â”œâ”€â”€ æ—¥æœ¬èªæ‹¡å¼µå‡¦ç†: 1000ms
â”œâ”€â”€ ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–: 2000ms
â””â”€â”€ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿çµ±åˆ: 500ms
Total: 19000ms (19s)

æ³¨æ„: PLaMoå‡¦ç†ãŒå…¨ä½“ã®80%ã‚’å ã‚ã‚‹
```

---

## ğŸ“ˆ **ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºåˆ¥è©³ç´°åˆ†æ**

### **å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ100-1,000è¡Œï¼‰**

#### **æ¨å¥¨è¨­å®š**
```rst
.. jsontable-rag:: small_data.json
   :header:
   :rag-enabled:
   :semantic-chunks:
   :chunk-strategy: fixed-size
   :export-formats: facets-only
```

#### **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§**
- âš¡ **å‡¦ç†æ™‚é–“**: 50-200msï¼ˆè¨±å®¹ç¯„å›²ï¼‰
- ğŸ§  **ãƒ¡ãƒ¢ãƒª**: 50-80MBï¼ˆè»½é‡ï¼‰
- ğŸ¯ **æœ€é©åŒ–**: ä¸è¦ï¼ˆååˆ†é«˜é€Ÿï¼‰

### **ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ1,000-10,000è¡Œï¼‰**

#### **æ¨å¥¨è¨­å®š**
```rst
.. jsontable-rag:: medium_data.json
   :header:
   :rag-enabled:
   :semantic-chunks:
   :advanced-metadata:
   :chunk-strategy: adaptive
   :export-formats: json-ld,statistics
```

#### **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§**
- âš¡ **å‡¦ç†æ™‚é–“**: 200ms-2sï¼ˆè¦ç›£è¦–ï¼‰
- ğŸ§  **ãƒ¡ãƒ¢ãƒª**: 80-150MBï¼ˆä¸­ç¨‹åº¦ï¼‰
- ğŸ¯ **æœ€é©åŒ–**: ãƒãƒƒãƒã‚µã‚¤ã‚ºèª¿æ•´æ¨å¥¨

### **å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ10,000-100,000è¡Œï¼‰**

#### **æ¨å¥¨è¨­å®š**
```rst
.. jsontable-rag:: large_data.json
   :header:
   :rag-enabled:
   :semantic-chunks:
   :advanced-metadata:
   :limit: 10000
   :chunk-strategy: fixed-size
   :export-formats: statistics
```

#### **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§**
- âš¡ **å‡¦ç†æ™‚é–“**: 2-20sï¼ˆè¦æœ€é©åŒ–ï¼‰
- ğŸ§  **ãƒ¡ãƒ¢ãƒª**: 150-500MBï¼ˆé‡é‡ç´šï¼‰
- ğŸ¯ **æœ€é©åŒ–**: å¿…é ˆï¼ˆãƒãƒƒãƒå‡¦ç†ãƒ»ä¸¦åˆ—åŒ–ï¼‰

### **è¶…å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ100,000è¡Œ+ï¼‰**

#### **æ¨å¥¨è¨­å®š**
```rst
.. jsontable-rag:: huge_data.json
   :header:
   :rag-enabled:
   :limit: 5000
   :chunk-strategy: fixed-size
   :export-formats: quality-report
```

#### **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§**
- âš¡ **å‡¦ç†æ™‚é–“**: 20s+ï¼ˆåˆ†å‰²å‡¦ç†æ¨å¥¨ï¼‰
- ğŸ§  **ãƒ¡ãƒ¢ãƒª**: 500MB+ï¼ˆè¦ç›£è¦–ï¼‰
- ğŸ¯ **æœ€é©åŒ–**: å¿…é ˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ï¼‰

---

## ğŸš€ **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æˆ¦ç•¥**

### **è¨­å®šãƒ¬ãƒ™ãƒ«æœ€é©åŒ–**

#### **è»½é‡è¨­å®šï¼ˆé€Ÿåº¦å„ªå…ˆï¼‰**
```python
# conf.py - è»½é‡è¨­å®š
rag_processing_batch_size = 2000
rag_parallel_workers = 2
rag_memory_limit = "256MB"
rag_enable_streaming = True

# è»½é‡ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
rag_default_chunk_strategy = "fixed-size"
rag_default_export_formats = ["statistics"]
```

#### **ãƒãƒ©ãƒ³ã‚¹è¨­å®šï¼ˆæ¨™æº–ï¼‰**
```python
# conf.py - ãƒãƒ©ãƒ³ã‚¹è¨­å®š
rag_processing_batch_size = 1000
rag_parallel_workers = 4
rag_memory_limit = "512MB"
rag_enable_streaming = True

# ãƒãƒ©ãƒ³ã‚¹ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
rag_default_chunk_strategy = "adaptive"
rag_default_export_formats = ["json-ld", "statistics"]
```

#### **é«˜æ©Ÿèƒ½è¨­å®šï¼ˆå“è³ªå„ªå…ˆï¼‰**
```python
# conf.py - é«˜æ©Ÿèƒ½è¨­å®š
rag_processing_batch_size = 500
rag_parallel_workers = 6
rag_memory_limit = "1GB"
rag_enable_caching = True

# é«˜æ©Ÿèƒ½ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
rag_default_chunk_strategy = "japanese-adaptive"
rag_default_export_formats = ["json-ld", "opensearch", "plamo-ready"]
```

### **å®Ÿè£…ãƒ¬ãƒ™ãƒ«æœ€é©åŒ–**

#### **ä¸¦åˆ—å‡¦ç†ã®æ´»ç”¨**
```python
# ä¸¦åˆ—ãƒãƒ£ãƒ³ã‚¯å‡¦ç†
async def process_large_dataset_parallel(data):
    batch_size = 1000
    batches = [data[i:i+batch_size] for i in range(0, len(data), batch_size)]
    
    tasks = []
    for batch in batches:
        task = asyncio.create_task(process_batch(batch))
        tasks.append(task)
    
    results = await asyncio.gather(*tasks)
    return merge_results(results)
```

#### **ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–**
```python
# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†
def process_streaming(data_iterator):
    for batch in chunked(data_iterator, batch_size=500):
        yield process_batch(batch)
        gc.collect()  # æ˜ç¤ºçš„ãƒ¡ãƒ¢ãƒªè§£æ”¾
```

#### **ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨**
```python
# LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹é«˜é€ŸåŒ–
from functools import lru_cache

@lru_cache(maxsize=1000)
def cached_entity_recognition(text_hash):
    return expensive_entity_recognition(text)
```

---

## ğŸ“Š **ç›£è¦–ãƒ»ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°**

### **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–æŒ‡æ¨™**

#### **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–**
```yaml
Real-time Metrics:
  response_time:
    p50: 500ms
    p95: 2000ms
    p99: 5000ms
  memory_usage:
    current: 256MB
    peak: 512MB
    limit: 1GB
  cpu_usage:
    average: 30%
    peak: 80%
  error_rate: 0.1%
```

#### **ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**
```python
# Prometheus ãƒ¡ãƒˆãƒªã‚¯ã‚¹
rag_processing_duration = Histogram(
    'rag_processing_duration_seconds',
    'RAG processing duration',
    ['phase', 'data_size']
)

rag_memory_usage = Gauge(
    'rag_memory_usage_bytes',
    'RAG memory usage',
    ['component']
)

rag_processing_count = Counter(
    'rag_processing_total',
    'Total RAG processing count',
    ['status', 'data_type']
)
```

### **ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æ‰‹æ³•**

#### **Python ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°**
```python
# cProfileã«ã‚ˆã‚‹è©³ç´°åˆ†æ
import cProfile
import pstats

def profile_rag_processing():
    profiler = cProfile.Profile()
    profiler.enable()
    
    # RAGå‡¦ç†å®Ÿè¡Œ
    result = process_rag_pipeline(data)
    
    profiler.disable()
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(20)  # ä¸Šä½20é–¢æ•°
```

#### **ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°**
```python
# memory_profilerã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªåˆ†æ
from memory_profiler import profile

@profile
def memory_intensive_rag_function():
    # RAGå‡¦ç†ã®å®Ÿè£…
    pass
```

---

## âš™ï¸ **ç’°å¢ƒåˆ¥æœ€é©åŒ–ã‚¬ã‚¤ãƒ‰**

### **é–‹ç™ºç’°å¢ƒ**

#### **è¨­å®šä¾‹**
```python
# conf_dev.py
rag_debug_mode = True
rag_processing_batch_size = 10
rag_parallel_workers = 1
jsontable_max_rows = 100

# é–‹ç™ºç”¨è»½é‡è¨­å®š
rag_enable_profiling = True
rag_detailed_logging = True
```

#### **æœ€é©åŒ–ãƒã‚¤ãƒ³ãƒˆ**
- ğŸ”§ **é«˜é€Ÿãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**: å°ãƒ‡ãƒ¼ã‚¿ã§ã®è¿…é€Ÿæ¤œè¨¼
- ğŸ“Š **è©³ç´°ãƒ­ã‚°**: å•é¡Œç‰¹å®šã®ãŸã‚ã®æƒ…å ±å……å®Ÿ
- ğŸ› **ãƒ‡ãƒãƒƒã‚°æ”¯æ´**: ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ»ãƒˆãƒ¬ãƒ¼ã‚¹æœ‰åŠ¹

### **ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒ**

#### **è¨­å®šä¾‹**
```python
# conf_staging.py
rag_debug_mode = False
rag_processing_batch_size = 500
rag_parallel_workers = 2
jsontable_max_rows = 5000

# æœ¬ç•ªé¡ä¼¼è¨­å®š
rag_enable_monitoring = True
rag_performance_logging = True
```

#### **æœ€é©åŒ–ãƒã‚¤ãƒ³ãƒˆ**
- ğŸ“ˆ **æœ¬ç•ªé¡ä¼¼**: æœ¬ç•ªç’°å¢ƒã§ã®æ€§èƒ½äºˆæ¸¬
- ğŸ” **è² è·ãƒ†ã‚¹ãƒˆ**: æ€§èƒ½é™ç•Œã®ç¢ºèª
- ğŸ“Š **ç›£è¦–æ¤œè¨¼**: ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®å‹•ä½œç¢ºèª

### **æœ¬ç•ªç’°å¢ƒ**

#### **è¨­å®šä¾‹**
```python
# conf_prod.py
rag_debug_mode = False
rag_processing_batch_size = 2000
rag_parallel_workers = 6
jsontable_max_rows = 10000

# æœ¬ç•ªæœ€é©åŒ–è¨­å®š
rag_enable_caching = True
rag_memory_optimization = True
rag_error_recovery = True
```

#### **æœ€é©åŒ–ãƒã‚¤ãƒ³ãƒˆ**
- ğŸš€ **å®‰å®šæ€§é‡è¦–**: ã‚¨ãƒ©ãƒ¼å›å¾©ãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
- ğŸ“Š **åŠ¹ç‡æ€§é‡è¦–**: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»æœ€é©åŒ–æ©Ÿèƒ½
- ğŸ”’ **ç›£è¦–å¼·åŒ–**: è©³ç´°ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–

---

## ğŸ¯ **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ»æ€§èƒ½ãƒ†ã‚¹ãƒˆ**

### **æ¨™æº–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯**

#### **å‡¦ç†æ™‚é–“ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯**
```python
import time
import pytest

@pytest.mark.benchmark
def test_rag_processing_performance():
    data = generate_test_data(size=1000)
    
    start_time = time.time()
    result = process_rag_pipeline(data)
    end_time = time.time()
    
    processing_time = end_time - start_time
    
    # æ€§èƒ½ç›®æ¨™: 1000è¡Œã§2ç§’ä»¥å†…
    assert processing_time < 2.0
    assert result.basic_metadata is not None
```

#### **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯**
```python
import psutil
import os

def test_memory_usage():
    process = psutil.Process(os.getpid())
    initial_memory = process.memory_info().rss
    
    # RAGå‡¦ç†å®Ÿè¡Œ
    data = generate_test_data(size=5000)
    result = process_rag_pipeline(data)
    
    peak_memory = process.memory_info().rss
    memory_increase = peak_memory - initial_memory
    
    # ç›®æ¨™: 5000è¡Œã§500MBä»¥å†…
    assert memory_increase < 500 * 1024 * 1024
```

### **è² è·ãƒ†ã‚¹ãƒˆ**

#### **åŒæ™‚å‡¦ç†ãƒ†ã‚¹ãƒˆ**
```python
import concurrent.futures
import threading

def test_concurrent_processing():
    def process_worker(worker_id):
        data = generate_test_data(size=500)
        return process_rag_pipeline(data)
    
    # 10åŒæ™‚å‡¦ç†
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(process_worker, i) for i in range(10)]
        results = [future.result() for future in futures]
    
    # å…¨ã¦æˆåŠŸã™ã‚‹ã“ã¨ã‚’ç¢ºèª
    assert len(results) == 10
    assert all(r.basic_metadata is not None for r in results)
```

#### **å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ**
```python
def test_large_data_processing():
    # 100,000è¡Œã®å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿
    large_data = generate_test_data(size=100000)
    
    start_time = time.time()
    result = process_rag_pipeline(large_data)
    end_time = time.time()
    
    # ç›®æ¨™: 100,000è¡Œã§60ç§’ä»¥å†…
    assert end_time - start_time < 60.0
    assert result.basic_metadata is not None
```

---

## ğŸ›¡ï¸ **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã®å¯¾ç­–**

### **ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–**

#### **å•é¡Œ1: ãƒ¡ãƒ¢ãƒªä¸è¶³**
```python
# ç—‡çŠ¶
MemoryError: Unable to allocate array

# åŸå› åˆ†æ
- å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ã®ä¸€æ‹¬å‡¦ç†
- ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚„ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸è¶³

# è§£æ±ºç­–
rag_processing_batch_size = 500      # ãƒãƒƒãƒã‚µã‚¤ã‚ºå‰Šæ¸›
rag_enable_streaming = True          # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†
rag_memory_limit = "256MB"           # ãƒ¡ãƒ¢ãƒªåˆ¶é™å¼·åŒ–
```

#### **å•é¡Œ2: å‡¦ç†æ™‚é–“éå¤§**
```python
# ç—‡çŠ¶
å‡¦ç†æ™‚é–“ãŒ10ç§’ä»¥ä¸Š

# åŸå› åˆ†æ
- é‡ã„æ©Ÿèƒ½ã®åŒæ™‚æœ‰åŠ¹åŒ–
- éåŠ¹ç‡ãªãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥

# è§£æ±ºç­–
:chunk-strategy: fixed-size          # è»½é‡æˆ¦ç•¥é¸æŠ
:export-formats: statistics          # å‡ºåŠ›å½¢å¼åˆ¶é™
:limit: 5000                         # ãƒ‡ãƒ¼ã‚¿é‡åˆ¶é™
```

#### **å•é¡Œ3: CPUä½¿ç”¨ç‡éå¤§**
```python
# ç—‡çŠ¶
CPUä½¿ç”¨ç‡90%ä»¥ä¸Š

# åŸå› åˆ†æ
- ä¸¦åˆ—å‡¦ç†æ•°ã®éè¨­å®š
- é‡ã„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ä½¿ç”¨

# è§£æ±ºç­–
rag_parallel_workers = 2             # ä¸¦åˆ—æ•°å‰Šæ¸›
rag_cpu_limit = 80                   # CPUåˆ¶é™è¨­å®š
```

### **ç·Šæ€¥å¯¾å¿œæ‰‹é †**

#### **ãƒ¬ãƒ™ãƒ«1: è¨­å®šèª¿æ•´**
```bash
# 1. è»½é‡è¨­å®šã¸ã®å¤‰æ›´
sed -i 's/japanese-adaptive/fixed-size/g' conf.py
sed -i 's/rag_parallel_workers = 8/rag_parallel_workers = 2/g' conf.py

# 2. Sphinxå†èµ·å‹•
systemctl restart sphinx-autobuild
```

#### **ãƒ¬ãƒ™ãƒ«2: æ©Ÿèƒ½åˆ¶é™**
```bash
# 1. é«˜è² è·æ©Ÿèƒ½ã®ç„¡åŠ¹åŒ–
sed -i 's/:advanced-metadata:/#:advanced-metadata:/g' source/*.rst
sed -i 's/:facet-generation:/#:facet-generation:/g' source/*.rst

# 2. å†ãƒ“ãƒ«ãƒ‰
sphinx-build -b html source build
```

#### **ãƒ¬ãƒ™ãƒ«3: RAGå®Œå…¨ç„¡åŠ¹åŒ–**
```bash
# 1. RAGãƒ‡ã‚£ãƒ¬ã‚¯ãƒ†ã‚£ãƒ–ã®ç„¡åŠ¹åŒ–
sed -i 's/jsontable-rag/jsontable/g' source/*.rst

# 2. RAGè¨­å®šã®ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
sed -i 's/^rag_/#rag_/g' conf.py
```

---

## ğŸ† **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®ç·æ‹¬**

### **æœ€é©åŒ–ã«ã‚ˆã‚‹åŠ¹æœ**

| æœ€é©åŒ–é …ç›® | åŠ¹æœ | å®Ÿè£…é›£æ˜“åº¦ | æ¨å¥¨åº¦ |
|------------|------|------------|--------|
| **ãƒãƒƒãƒã‚µã‚¤ã‚ºèª¿æ•´** | 30-50%æ”¹å–„ | æ˜“ | â­â­â­â­â­ |
| **ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–** | 50-80%æ”¹å–„ | ä¸­ | â­â­â­â­ |
| **ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥é¸æŠ** | 20-70%æ”¹å–„ | æ˜“ | â­â­â­â­â­ |
| **ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨** | 80-95%æ”¹å–„ | ä¸­ | â­â­â­â­ |
| **ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†** | ãƒ¡ãƒ¢ãƒª70%å‰Šæ¸› | é›£ | â­â­â­ |

### **æ¨å¥¨æœ€é©åŒ–ãƒ‘ã‚¹**

#### **Phase 1: åŸºæœ¬æœ€é©åŒ–ï¼ˆå³åŠ¹æ€§ï¼‰**
1. ãƒãƒƒãƒã‚µã‚¤ã‚ºãƒ»ä¸¦åˆ—æ•°ã®èª¿æ•´
2. ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ã®æœ€é©åŒ–
3. å‡ºåŠ›å½¢å¼ã®é¸æŠçš„æœ‰åŠ¹åŒ–

#### **Phase 2: é«˜åº¦æœ€é©åŒ–ï¼ˆä¸­æœŸï¼‰**
1. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã®å°å…¥
2. ç›£è¦–ãƒ»ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å¼·åŒ–
3. ç’°å¢ƒåˆ¥è¨­å®šã®æœ€é©åŒ–

#### **Phase 3: æœ€é«˜åº¦æœ€é©åŒ–ï¼ˆé•·æœŸï¼‰**
1. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã®å®Ÿè£…
2. ã‚«ã‚¹ã‚¿ãƒ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é–‹ç™º
3. ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æœ€é©åŒ–

### **æˆåŠŸæŒ‡æ¨™**
- âš¡ **å¿œç­”æ™‚é–“**: ç›®æ¨™å€¤ä»¥å†…ã®é”æˆ
- ğŸ§  **ãƒ¡ãƒ¢ãƒªåŠ¹ç‡**: ä½¿ç”¨é‡50%å‰Šæ¸›
- ğŸ“ˆ **ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: å‡¦ç†èƒ½åŠ›2å€å‘ä¸Š
- ğŸ¯ **å®‰å®šæ€§**: ã‚¨ãƒ©ãƒ¼ç‡0.1%ä»¥ä¸‹

**çµè«–**: é©åˆ‡ãªæœ€é©åŒ–ã«ã‚ˆã‚Šã€v0.3.0ã¯å¾“æ¥æ¯”ã§å¤§å¹…ãªæ€§èƒ½å‘ä¸Šã¨æ©Ÿèƒ½æ‹¡å¼µã‚’ä¸¡ç«‹ã§ãã¾ã™ã€‚æ®µéšçš„æœ€é©åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚Šã€ç¢ºå®Ÿã«é«˜æ€§èƒ½ãªRAGã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã—ã¾ã—ã‚‡ã†ï¼ ğŸš€