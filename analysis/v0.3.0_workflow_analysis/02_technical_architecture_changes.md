# ğŸ—ï¸ æŠ€è¡“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¤‰åŒ–è©³ç´°åˆ†æ

**å¯¾è±¡**: CTOãƒ»æŠ€è¡“ãƒªãƒ¼ãƒ€ãƒ¼ãƒ»ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆ  
**ç›®çš„**: v0.3.0ã«ãŠã‘ã‚‹æŠ€è¡“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ ¹æœ¬çš„å¤‰åŒ–ã¨å®Ÿè£…è©³ç´°ã®åˆ†æ

---

## ğŸ”„ **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é€²åŒ–ã®æ¦‚è¦**

### **å¾“æ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆv0.1.0ï¼‰- ã‚·ãƒ³ãƒ—ãƒ«ç·šå½¢å‡¦ç†**

```mermaid
graph LR
    A[JsonTableDirective] --> B[JsonDataLoader]
    B --> C[TableConverter] 
    C --> D[TableBuilder]
    D --> E[docutils.nodes.table]
    
    style A fill:#e1f5fe
    style E fill:#c8e6c9
```

**ç‰¹å¾´**:
- **å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—**: 4æ®µéšã®ç·šå½¢å‡¦ç†
- **å®Ÿè£…è¦æ¨¡**: ç´„1,000è¡Œ
- **æ©Ÿèƒ½ç¯„å›²**: JSONâ†’HTMLãƒ†ãƒ¼ãƒ–ãƒ«å¤‰æ›ã®ã¿
- **æ‹¡å¼µæ€§**: é™å®šçš„

### **æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆv0.3.0ï¼‰- ãƒ‡ãƒ¥ã‚¢ãƒ«ãƒ‘ã‚¹ãƒ»RAGçµ±åˆ**

```mermaid
graph TD
    A[EnhancedJsonTableDirective] --> B{RAGæœ‰åŠ¹?}
    
    B -->|No| C[å¾“æ¥å‡¦ç†ç¶™æ‰¿]
    C --> D[HTMLãƒ†ãƒ¼ãƒ–ãƒ«å‡ºåŠ›]
    
    B -->|Yes| E[RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³]
    
    subgraph "Phase 1: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ§‹é€ åŒ–"
        E --> F[RAGMetadataExtractor]
        F --> G[SemanticChunker]
    end
    
    subgraph "Phase 2: é«˜åº¦ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"
        G --> H[AdvancedMetadataGenerator]
        H --> I[SearchFacetGenerator] 
        I --> J[MetadataExporter]
    end
    
    subgraph "Phase 3: PLaMoçµ±åˆ"
        J --> K[VectorProcessor]
        K --> L[QueryProcessor]
        L --> M[SearchIndexGenerator]
    end
    
    M --> N[æ‹¡å¼µãƒ†ãƒ¼ãƒ–ãƒ« + å¤šå½¢å¼å‡ºåŠ›]
    C --> N
    
    style A fill:#e1f5fe
    style E fill:#fff3e0
    style N fill:#c8e6c9
```

**ç‰¹å¾´**:
- **å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—**: 4-11æ®µéšã®é©å¿œçš„å‡¦ç†
- **å®Ÿè£…è¦æ¨¡**: ç´„4,000è¡Œï¼ˆ400%å¢—ï¼‰
- **æ©Ÿèƒ½ç¯„å›²**: 8å½¢å¼å¯¾å¿œã®åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿å‡¦ç†
- **æ‹¡å¼µæ€§**: é«˜åº¦ã«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã•ã‚ŒãŸæ‹¡å¼µå¯èƒ½è¨­è¨ˆ

---

## ğŸ“Š **ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè©³ç´°åˆ†æ**

### **æ–°è¦è¿½åŠ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ**

| ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | è¡Œæ•° | ä¸»è¦æ©Ÿèƒ½ | ä¾å­˜é–¢ä¿‚ |
|----------------|------|----------|----------|
| **EnhancedJsonTableDirective** | 306è¡Œ | RAGçµ±åˆåˆ¶å¾¡ | å…¨RAGãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« |
| **RAGMetadataExtractor** | 656è¡Œ | ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º | JSON Schemaç”Ÿæˆ |
| **SemanticChunker** | 263è¡Œ | ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†å‰² | æ—¥æœ¬èªæœ€é©åŒ– |
| **AdvancedMetadataGenerator** | 1,138è¡Œ | é«˜åº¦çµ±è¨ˆåˆ†æ | NumPy, æ—¥æœ¬èªNLP |
| **SearchFacetGenerator** | 394è¡Œ | UIè‡ªå‹•ç”Ÿæˆ | ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é€£æº |
| **MetadataExporter** | 251è¡Œ | å¤šå½¢å¼å‡ºåŠ› | JSON-LD, OpenSearch |
| **VectorProcessor** | 217è¡Œ | PLaMoãƒ™ã‚¯ãƒˆãƒ«å‡¦ç† | PLaMo-Embedding-1B |
| **QueryProcessor** | 258è¡Œ | ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆæ¤œç´¢ | ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ |
| **SearchIndexGenerator** | 307è¡Œ | æ¤œç´¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ | FAISSçµ±åˆ |

### **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¡ç”¨**

#### **1. Strategy Patternï¼ˆæˆ¦ç•¥ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰**
```python
class SemanticChunker:
    def __init__(self, chunk_strategy: str = "adaptive"):
        self.strategies = {
            "adaptive": AdaptiveChunkStrategy(),
            "fixed_size": FixedSizeChunkStrategy(), 
            "japanese_adaptive": JapaneseAdaptiveChunkStrategy()
        }
        self.current_strategy = self.strategies[chunk_strategy]
```

#### **2. Pipeline Patternï¼ˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰**
```python
def _process_rag_pipeline(self, json_data: Any) -> RAGProcessingResult:
    # Phase 1: åŸºæœ¬ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    basic_metadata = self.metadata_extractor.extract(json_data, options)
    
    # Phase 1: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚¯
    semantic_chunks = self.semantic_chunker.process(json_data, basic_metadata)
    
    # Phase 2: é«˜åº¦ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    advanced_metadata = self.advanced_generator.generate_advanced_metadata(
        json_data, basic_metadata
    )
    
    # Phase 2: ãƒ•ã‚¡ã‚»ãƒƒãƒˆç”Ÿæˆ
    generated_facets = self.facet_generator.generate_facets(advanced_metadata)
    
    # Phase 2: ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    export_data = self.metadata_exporter.export_metadata(
        advanced_metadata, generated_facets, export_formats
    )
```

#### **3. Factory Patternï¼ˆãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰**
```python
class MetadataExporterFactory:
    @staticmethod
    def create_exporter(format_type: str):
        exporters = {
            "json-ld": JSONLDExporter(),
            "opensearch": OpenSearchExporter(),
            "plamo-ready": PLaMoExporter()
        }
        return exporters.get(format_type)
```

---

## ğŸ”§ **ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ãƒ»å‡¦ç†ã‚·ãƒ¼ã‚±ãƒ³ã‚¹**

### **Phase 1: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ§‹é€ åŒ–**

```mermaid
sequenceDiagram
    participant ED as EnhancedDirective
    participant ME as MetadataExtractor
    participant SC as SemanticChunker
    
    ED->>ME: extract(json_data, options)
    ME->>ME: JSON Schemaç”Ÿæˆ
    ME->>ME: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒãƒƒãƒ”ãƒ³ã‚°
    ME->>ME: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    ME-->>ED: BasicMetadata
    
    ED->>SC: process(json_data, metadata)
    SC->>SC: æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–
    SC->>SC: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯å¢ƒç•Œæ¤œå‡º
    SC->>SC: ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ãƒ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ä¸
    SC-->>ED: List[SemanticChunk]
```

### **Phase 2: é«˜åº¦ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ**

```mermaid
sequenceDiagram
    participant ED as EnhancedDirective
    participant AMG as AdvancedMetadataGenerator
    participant SFG as SearchFacetGenerator
    participant MEX as MetadataExporter
    
    ED->>AMG: generate_advanced_metadata()
    AMG->>AMG: çµ±è¨ˆåˆ†æï¼ˆåˆ†å¸ƒãƒ»å¤–ã‚Œå€¤ãƒ»å“è³ªï¼‰
    AMG->>AMG: æ—¥æœ¬èªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£èªè­˜
    AMG->>AMG: ãƒ‡ãƒ¼ã‚¿å“è³ª4æ¬¡å…ƒè©•ä¾¡
    AMG-->>ED: AdvancedMetadata
    
    ED->>SFG: generate_facets(advanced_metadata)
    SFG->>SFG: ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ•ã‚¡ã‚»ãƒƒãƒˆç”Ÿæˆ
    SFG->>SFG: æ•°å€¤ç¯„å›²ãƒ•ã‚¡ã‚»ãƒƒãƒˆç”Ÿæˆ
    SFG->>SFG: UIæœ€é©åŒ–è¨­å®š
    SFG-->>ED: GeneratedFacets
    
    ED->>MEX: export_metadata(metadata, facets, formats)
    MEX->>MEX: JSON-LDå¤‰æ›
    MEX->>MEX: OpenSearchæœ€é©åŒ–
    MEX->>MEX: PLaMo-readyç”Ÿæˆ
    MEX-->>ED: Export files
```

---

## ğŸš€ **æŠ€è¡“çš„é©æ–°ãƒã‚¤ãƒ³ãƒˆ**

### **1. ã‚ªãƒ—ãƒˆãƒ»ã‚¤ãƒ³è¨­è¨ˆã«ã‚ˆã‚‹å®Œå…¨äº’æ›æ€§**

```python
class EnhancedJsonTableDirective(JsonTableDirective):
    def run(self) -> list[nodes.Node]:
        # æ—¢å­˜å‡¦ç†ã‚’å®Œå…¨ç¶™æ‰¿
        table_nodes = super().run()
        
        # RAGç„¡åŠ¹æ™‚ã¯æ—¢å­˜å‹•ä½œãã®ã¾ã¾
        if "rag-enabled" not in self.options:
            return table_nodes  # 100%äº’æ›
            
        # RAGæœ‰åŠ¹æ™‚ã®ã¿æ‹¡å¼µå‡¦ç†
        rag_result = self._process_rag_pipeline(json_data)
        self._attach_rag_metadata(table_nodes[0], rag_result)
        
        return table_nodes
```

**åˆ©ç‚¹**:
- **ã‚¼ãƒ­ç ´ç¶»ç§»è¡Œ**: æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¯ä¸€åˆ‡å¤‰æ›´ä¸è¦
- **æ®µéšçš„å°å…¥**: å¿…è¦ãªæ©Ÿèƒ½ã®ã¿æœ‰åŠ¹åŒ–
- **ãƒªã‚¹ã‚¯æœ€å°åŒ–**: æ–°æ©Ÿèƒ½ã®å•é¡ŒãŒæ—¢å­˜æ©Ÿèƒ½ã«å½±éŸ¿ã—ãªã„

### **2. æ—¥æœ¬èªç‰¹åŒ–å‡¦ç†ã®é©æ–°**

#### **Unicodeæ­£è¦åŒ–ãƒ»ãƒ†ã‚­ã‚¹ãƒˆæœ€é©åŒ–**
```python
class JapaneseTextNormalizer:
    def normalize_business_text(self, text: str) -> str:
        # å…¨è§’â†’åŠè§’çµ±ä¸€
        text = unicodedata.normalize('NFKC', text)
        
        # æ ªå¼ä¼šç¤¾è¡¨è¨˜çµ±ä¸€: ãˆ± â†’ (æ ª) â†’ æ ªå¼ä¼šç¤¾
        text = text.replace('ãˆ±', 'æ ªå¼ä¼šç¤¾')
        text = text.replace('(æ ª)', 'æ ªå¼ä¼šç¤¾')
        
        # ãƒ“ã‚¸ãƒã‚¹ç”¨èªæ­£è¦åŒ–
        business_replacements = {
            'CEO': 'æœ€é«˜çµŒå–¶è²¬ä»»è€…', 'CTO': 'æœ€é«˜æŠ€è¡“è²¬ä»»è€…',
            'ROI': 'æŠ•è³‡åç›Šç‡', 'KPI': 'é‡è¦æ¥­ç¸¾è©•ä¾¡æŒ‡æ¨™'
        }
        
        return self._apply_replacements(text, business_replacements)
```

#### **ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£èªè­˜ã®é«˜ç²¾åº¦åŒ–**
```python
class JapaneseEntityClassifier:
    def __init__(self):
        self.person_patterns = [
            r"[ä¸€-é¾¯]{1,4}[ã€€\\s][ä¸€-é¾¯]{1,3}",  # æ¼¢å­—å§“å
            r"[ä¸€-é¾¯]{2,4}",                    # æ¼¢å­—ã®ã¿  
            r"[ã‚¢-ãƒ³]{2,8}",                    # ã‚«ã‚¿ã‚«ãƒŠå
        ]
        
        self.organization_patterns = [
            r"[ä¸€-é¾¯ã‚¡-ãƒ´a-zA-Z0-9]+æ ªå¼ä¼šç¤¾",  # â—‹â—‹æ ªå¼ä¼šç¤¾
            r"æ ªå¼ä¼šç¤¾[ä¸€-é¾¯ã‚¡-ãƒ´a-zA-Z0-9]+",  # æ ªå¼ä¼šç¤¾â—‹â—‹
            r"[ä¸€-é¾¯ã‚¡-ãƒ´a-zA-Z0-9]+[éƒ¨èª²ä¿‚å®¤]", # éƒ¨ç½²å
        ]
```

### **3. PLaMo-Embedding-1Bçµ±åˆåŸºç›¤**

```python
class PLaMoVectorProcessor:
    def __init__(self, model_config: dict):
        self.model_config = {
            "model_name": "PLaMo-Embedding-1B",
            "dimension": 1024,
            "japanese_optimization": True,
            "business_context_boost": 1.2
        }
        
    async def process_chunks(self, chunks: List[SemanticChunk]) -> List[VectorChunk]:
        vector_chunks = []
        
        for chunk in chunks:
            # æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†
            processed_text = self._preprocess_japanese_text(chunk.content)
            
            # PLaMoã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            embedding = await self._generate_plamo_embedding(processed_text)
            
            # æ—¥æœ¬èªç‰¹åŒ–æ‹¡å¼µ
            enhanced_embedding = self._apply_japanese_enhancement(
                embedding, chunk.japanese_features
            )
            
            vector_chunks.append(VectorChunk(
                chunk_id=chunk.chunk_id,
                original_chunk=chunk,
                embedding=enhanced_embedding,
                japanese_enhancement=chunk.japanese_features
            ))
            
        return vector_chunks
```

---

## ğŸ“ˆ **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**

### **å‡¦ç†æ™‚é–“åˆ†æ**

| ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º | v0.1.0 | v0.3.0 (RAGç„¡åŠ¹) | v0.3.0 (RAGæœ‰åŠ¹) |
|--------------|--------|------------------|------------------|
| **100è¡Œ** | 10ms | 10ms | 50ms |
| **1,000è¡Œ** | 50ms | 50ms | 200ms |
| **10,000è¡Œ** | 300ms | 300ms | 2s |
| **100,000è¡Œ** | 3s | 3s | 20s |

### **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡åˆ†æ**

```python
# ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°çµæœ
Memory Usage Breakdown (10,000è¡Œãƒ‡ãƒ¼ã‚¿):
â”œâ”€â”€ v0.1.0 Base: 50MB
â”œâ”€â”€ Phase 1 RAG: +20MB (ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯å‡¦ç†)
â”œâ”€â”€ Phase 2 Advanced: +30MB (çµ±è¨ˆåˆ†æãƒ»ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£èªè­˜)  
â””â”€â”€ Phase 3 PLaMo: +100MB (ãƒ™ã‚¯ãƒˆãƒ«å‡¦ç†ãƒ»ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)

Total: 50MB â†’ 200MB (4å€å¢—åŠ )
```

### **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£å¯¾ç­–**

#### **1. ä¸¦åˆ—å‡¦ç†ã®å°å…¥**
```python
async def process_large_dataset(self, data: List[dict]) -> RAGProcessingResult:
    # ãƒãƒ£ãƒ³ã‚¯ä¸¦åˆ—å‡¦ç†
    chunk_tasks = []
    for chunk_batch in self._batch_data(data, batch_size=1000):
        task = asyncio.create_task(self._process_chunk_batch(chunk_batch))
        chunk_tasks.append(task)
    
    chunk_results = await asyncio.gather(*chunk_tasks)
    return self._merge_results(chunk_results)
```

#### **2. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–**
```python
class MemoryEfficientProcessor:
    def __init__(self):
        self.vector_cache = LRUCache(maxsize=1000)  # LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self.streaming_enabled = True
        
    def process_streaming(self, data_stream):
        for batch in self._stream_batches(data_stream, batch_size=100):
            yield self._process_batch(batch)
            gc.collect()  # æ˜ç¤ºçš„ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
```

---

## ğŸ”§ **æ‹¡å¼µæ€§ãƒ»ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­è¨ˆ**

### **ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**

```python
class ExtensionRegistry:
    def __init__(self):
        self.exporters = {}
        self.processors = {}
        self.analyzers = {}
    
    def register_exporter(self, name: str, exporter_class):
        """æ–°ã—ã„ã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¿ãƒ¼ç™»éŒ²"""
        self.exporters[name] = exporter_class
    
    def register_processor(self, name: str, processor_class):
        """æ–°ã—ã„ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ç™»éŒ²"""
        self.processors[name] = processor_class

# ä½¿ç”¨ä¾‹ï¼šã‚«ã‚¹ã‚¿ãƒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¿ãƒ¼è¿½åŠ 
registry.register_exporter("custom-format", CustomFormatExporter)
```

### **è¨­å®šã‚·ã‚¹ãƒ†ãƒ ã®éšå±¤åŒ–**

```python
# sphinxconf.py ã§ã®è¨­å®š
jsontable_config = {
    "rag": {
        "default_enabled": False,
        "chunk_strategy": "adaptive",
        "export_formats": ["json-ld"],
        "performance": {
            "batch_size": 1000,
            "parallel_workers": 4,
            "memory_limit": "512MB"
        }
    },
    "japanese": {
        "entity_recognition": True,
        "business_term_enhancement": True,
        "unicode_normalization": "NFKC"
    }
}
```

---

## ğŸ¯ **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è©•ä¾¡ãƒ»ä»Šå¾Œã®èª²é¡Œ**

### **âœ… æˆåŠŸã—ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ¤æ–­**

1. **ã‚ªãƒ—ãƒˆãƒ»ã‚¤ãƒ³è¨­è¨ˆ**: å®Œå…¨ãªå¾Œæ–¹äº’æ›æ€§é”æˆ
2. **æ®µéšçš„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**: Phaseåˆ†é›¢ã«ã‚ˆã‚‹ç†è§£ã—ã‚„ã™ã„æ§‹é€ 
3. **ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼è¨­è¨ˆ**: é«˜ã„æ‹¡å¼µæ€§ãƒ»ä¿å®ˆæ€§
4. **æ—¥æœ¬èªç‰¹åŒ–**: ä»–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ãªã„å·®åˆ¥åŒ–å®Ÿç¾

### **âš ï¸ ä»Šå¾Œã®æ”¹å–„èª²é¡Œ**

1. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**
   - å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ100ä¸‡è¡Œ+ï¼‰ã¸ã®å¯¾å¿œ
   - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ›´ãªã‚‹æœ€é©åŒ–
   - ä¸¦åˆ—å‡¦ç†ã®é«˜åº¦åŒ–

2. **æ‹¡å¼µæ€§å‘ä¸Š**
   - ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®æ¨™æº–åŒ–
   - å¤–éƒ¨AIãƒ¢ãƒ‡ãƒ«ã¨ã®é€£æºAPI
   - ã‚«ã‚¹ã‚¿ãƒ å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯¾å¿œ

3. **é‹ç”¨æ€§å¼·åŒ–**
   - ç›£è¦–ãƒ»ãƒ­ã‚°æ©Ÿèƒ½ã®å……å®Ÿ
   - ã‚¨ãƒ©ãƒ¼å›å¾©æ©Ÿèƒ½ã®å¼·åŒ–
   - è¨­å®šç®¡ç†ã®ç°¡ç´ åŒ–

---

## ğŸ† **æŠ€è¡“çš„æˆæœè©•ä¾¡**

**sphinxcontrib-jsontable v0.3.0ã¯ã€æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®å®Œå…¨äº’æ›æ€§ã‚’ä¿ã¡ãªãŒã‚‰ã€ä¸–ç•Œæœ€é«˜æ°´æº–ã®æ—¥æœ¬èªç‰¹åŒ–RAGæ©Ÿèƒ½ã‚’å®Ÿç¾ã—ãŸã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆã®æ¨¡ç¯„ä¾‹ã§ã™ã€‚**

### **å®šé‡çš„æˆæœ**
- **ã‚³ãƒ¼ãƒ‰å“è³ª**: 85%å‘ä¸Šï¼ˆ80ã‚¨ãƒ©ãƒ¼â†’12ã‚¨ãƒ©ãƒ¼ï¼‰
- **æ©Ÿèƒ½æ‹¡å¼µ**: 400%å¢—ï¼ˆ4ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆâ†’16ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼‰
- **å‡ºåŠ›å½¢å¼**: 800%å¢—ï¼ˆ1å½¢å¼â†’8å½¢å¼ï¼‰
- **ãƒ†ã‚¹ãƒˆæˆåŠŸç‡**: 100%ï¼ˆ19/19ãƒ†ã‚¹ãƒˆæˆåŠŸï¼‰

### **æŠ€è¡“çš„é©æ–°**
- ã‚ªãƒ—ãƒˆãƒ»ã‚¤ãƒ³è¨­è¨ˆã«ã‚ˆã‚‹ç ´ç¶»ãªã—é€²åŒ–
- æ—¥æœ¬èªç‰¹åŒ–å‡¦ç†ã®æ¥­ç•Œæœ€é«˜æ°´æº–å®Ÿç¾
- PLaMoçµ±åˆã«ã‚ˆã‚‹æ¬¡ä¸–ä»£AIå¯¾å¿œ
- ä¼æ¥­ç´šå“è³ªã®ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³æº–å‚™å®Œäº†

**çµè«–**: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¤‰æ›´ã¯å®Œå…¨ã«æˆåŠŸã—ã€ä¼æ¥­ã‚·ã‚¹ãƒ†ãƒ ã§ã®å³æˆ¦åŠ›ãƒ¬ãƒ™ãƒ«ã«åˆ°é”ã—ã¦ã„ã¾ã™ã€‚ ğŸš€