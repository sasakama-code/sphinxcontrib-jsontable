"""
Phase 2çµ±åˆãƒ†ã‚¹ãƒˆ: å…¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé€£æºæ¤œè¨¼

çµ±åˆãƒ†ã‚¹ãƒˆã®ç›®çš„:
1. AdvancedMetadataGenerator, SearchFacetGenerator, MetadataExporter ã®é€£æº
2. æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã§ã®å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¤œè¨¼
3. å®Ÿç”¨çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç¢ºèª
4. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ¤œè¨¼
"""

import json
import tempfile
from pathlib import Path

import pytest

from sphinxcontrib.jsontable.rag.advanced_metadata import AdvancedMetadataGenerator
from sphinxcontrib.jsontable.rag.metadata_exporter import MetadataExporter
from sphinxcontrib.jsontable.rag.search_facets import SearchFacetGenerator


class TestPhase2Integration:
    """Phase 2å…¨ä½“çµ±åˆãƒ†ã‚¹ãƒˆ"""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆæº–å‚™"""
        self.advanced_generator = AdvancedMetadataGenerator()
        self.facet_generator = SearchFacetGenerator()
        self.metadata_exporter = MetadataExporter()

    @pytest.fixture
    def japanese_employee_data(self):
        """æ—¥æœ¬èªå¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«"""
        return [
            {
                "name": "ç”°ä¸­å¤ªéƒ",
                "age": 30,
                "department": "é–‹ç™ºéƒ¨",
                "salary": 700000,
                "email": "tanaka@company.co.jp",
                "hire_date": "2020-04-01",
                "skills": ["Python", "æ©Ÿæ¢°å­¦ç¿’", "ãƒ‡ãƒ¼ã‚¿åˆ†æ"],
                "position": "ã‚·ãƒ‹ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢"
            },
            {
                "name": "ä½è—¤èŠ±å­",
                "age": 28,
                "department": "å–¶æ¥­éƒ¨",
                "salary": 600000,
                "email": "sato@company.co.jp",
                "hire_date": "2021-07-15",
                "skills": ["å–¶æ¥­æˆ¦ç•¥", "é¡§å®¢ç®¡ç†", "ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³"],
                "position": "å–¶æ¥­ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"
            },
            {
                "name": "å±±ç”°æ¬¡éƒ",
                "age": 35,
                "department": "é–‹ç™ºéƒ¨",
                "salary": 850000,
                "email": "yamada@company.co.jp",
                "hire_date": "2018-03-01",
                "skills": ["Java", "ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ", "ãƒãƒ¼ãƒ ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—"],
                "position": "ãƒ†ãƒƒã‚¯ãƒªãƒ¼ãƒ‰"
            },
            {
                "name": "éˆ´æœ¨ç¾å’²",
                "age": 26,
                "department": "äººäº‹éƒ¨",
                "salary": 500000,
                "email": "suzuki@company.co.jp",
                "hire_date": "2022-01-10",
                "skills": ["æ¡ç”¨", "åŠ´å‹™ç®¡ç†", "äººæè‚²æˆ"],
                "position": "äººäº‹ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆ"
            }
        ]

    @pytest.fixture
    def business_data(self):
        """ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«"""
        return [
            {
                "product_name": "ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã‚¢ãƒ—ãƒªé–‹ç™ºã‚µãƒ¼ãƒ“ã‚¹",
                "category": "IT ã‚µãƒ¼ãƒ“ã‚¹",
                "price": 2000000,
                "client": "æ ªå¼ä¼šç¤¾ã‚¢ã‚¯ãƒ¡ãƒ†ãƒƒã‚¯",
                "project_duration": "3ãƒ¶æœˆ",
                "completion_date": "2024-03-15",
                "team_size": 5,
                "technologies": ["React Native", "Firebase", "Node.js"]
            },
            {
                "product_name": "Webã‚µã‚¤ãƒˆãƒªãƒ‹ãƒ¥ãƒ¼ã‚¢ãƒ«",
                "category": "IT ã‚µãƒ¼ãƒ“ã‚¹",  # categoryã‚’é‡è¤‡ã•ã›ã¦ãƒ•ã‚¡ã‚»ãƒƒãƒˆåŒ–å¯èƒ½ã«
                "price": 800000,
                "client": "æœ‰é™ä¼šç¤¾ãƒ™ã‚¹ãƒˆãƒ•ãƒ¼ã‚º",
                "project_duration": "2ãƒ¶æœˆ",
                "completion_date": "2024-02-20",
                "team_size": 3,
                "technologies": ["Vue.js", "WordPress", "PHP"]
            },
            {
                "product_name": "ãƒ‡ãƒ¼ã‚¿åˆ†æã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰",
                "category": "ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º",
                "price": 5000000,
                "client": "å¤§æ‰‹è£½é€ æ¥­Aç¤¾",
                "project_duration": "6ãƒ¶æœˆ",
                "completion_date": "2024-06-30",
                "team_size": 8,
                "technologies": ["Python", "PostgreSQL", "Apache Spark"]
            },
            {
                "product_name": "ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªä¿å®ˆ",
                "category": "IT ã‚µãƒ¼ãƒ“ã‚¹",  # categoryã‚’æ›´ã«é‡è¤‡ã•ã›ã‚‹
                "price": 1200000,
                "client": "æ ªå¼ä¼šç¤¾ãƒ†ãƒƒã‚¯ãƒ•ãƒ­ãƒ¼",
                "project_duration": "12ãƒ¶æœˆ",
                "completion_date": "2024-12-31",
                "team_size": 4,
                "technologies": ["React Native", "AWS", "MongoDB"]
            }
        ]

    def test_complete_pipeline_japanese_employees(self, japanese_employee_data):
        """æ—¥æœ¬èªå¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿ã§ã®å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""
        # åŸºæœ¬ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æº–å‚™
        basic_metadata = {
            "source_info": {"file_path": "employees.json", "data_type": "json"},
            "processing_timestamp": "2024-06-07T10:00:00Z",
            "rag_version": "2.0.0"
        }

        # Phase 2 Step 1: é«˜åº¦ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        advanced_metadata = self.advanced_generator.generate_advanced_metadata(
            json_data=japanese_employee_data,
            basic_metadata=basic_metadata
        )

        # çµ±è¨ˆåˆ†æçµæœã®æ¤œè¨¼
        assert "numerical_fields" in advanced_metadata.statistical_analysis
        assert "categorical_fields" in advanced_metadata.statistical_analysis
        
        # å¹´é½¢ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®çµ±è¨ˆåˆ†ææ¤œè¨¼
        age_stats = advanced_metadata.statistical_analysis["numerical_fields"].get("age")
        assert age_stats is not None
        assert age_stats["min_value"] == 26
        assert age_stats["max_value"] == 35
        assert 29 <= age_stats["mean"] <= 30  # å¹³å‡å¹´é½¢æ¤œè¨¼

        # éƒ¨ç½²ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã‚«ãƒ†ã‚´ãƒªåˆ†ææ¤œè¨¼
        dept_stats = advanced_metadata.statistical_analysis["categorical_fields"].get("department")
        assert dept_stats is not None
        assert "é–‹ç™ºéƒ¨" in dept_stats["value_counts"]
        assert dept_stats["value_counts"]["é–‹ç™ºéƒ¨"] == 2  # é–‹ç™ºéƒ¨ã¯2å

        # æ—¥æœ¬èªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ¤œè¨¼
        entities = advanced_metadata.entity_classification
        assert len(entities.persons) >= 4  # 4åã®åå‰ã‚’æ¤œå‡º
        
        # çµ„ç¹”ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ¤œè¨¼ï¼ˆéƒ¨ç½²åï¼‰
        detected_orgs = [org.organization for org in entities.organizations]
        expected_departments = ["é–‹ç™ºéƒ¨", "å–¶æ¥­éƒ¨", "äººäº‹éƒ¨"]
        for dept in expected_departments:
            assert any(dept in org for org in detected_orgs)

        # ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡æ¤œè¨¼
        quality = advanced_metadata.data_quality
        assert quality.overall_score >= 0.8  # é«˜å“è³ªãƒ‡ãƒ¼ã‚¿æœŸå¾…
        assert quality.completeness_score >= 0.9  # å®Œå…¨æ€§

        # Phase 2 Step 2: æ¤œç´¢ãƒ•ã‚¡ã‚»ãƒƒãƒˆç”Ÿæˆ
        generated_facets = self.facet_generator.generate_facets(advanced_metadata)

        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ•ã‚¡ã‚»ãƒƒãƒˆæ¤œè¨¼
        assert len(generated_facets.categorical_facets) >= 1
        dept_facet = next(
            (f for f in generated_facets.categorical_facets if f.field_name == "department"),
            None
        )
        assert dept_facet is not None
        assert dept_facet.display_name == "éƒ¨ç½²"
        assert "é–‹ç™ºéƒ¨" in dept_facet.values

        # æ•°å€¤ãƒ•ã‚¡ã‚»ãƒƒãƒˆæ¤œè¨¼
        assert len(generated_facets.numerical_facets) >= 2
        salary_facet = next(
            (f for f in generated_facets.numerical_facets if f.field_name == "salary"),
            None
        )
        assert salary_facet is not None
        assert salary_facet.display_name == "çµ¦ä¸"
        assert salary_facet.min_value == 500000
        assert salary_facet.max_value == 850000

        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ•ã‚¡ã‚»ãƒƒãƒˆæ¤œè¨¼
        assert len(generated_facets.entity_facets) >= 1
        person_facet = next(
            (f for f in generated_facets.entity_facets if f.entity_type == "persons"),
            None
        )
        assert person_facet is not None
        assert person_facet.display_name == "äººå"

        # Phase 2 Step 3: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›
        export_formats = ["json-ld", "opensearch", "plamo-ready"]
        exported_data = self.metadata_exporter.export_metadata(
            advanced_metadata=advanced_metadata,
            generated_facets=generated_facets,
            formats=export_formats
        )

        # JSON-LDå‡ºåŠ›æ¤œè¨¼
        assert "json-ld" in exported_data
        json_ld = exported_data["json-ld"]
        assert json_ld["@type"] == "Dataset"
        assert "rag:statisticalAnalysis" in json_ld
        assert "rag:entityClassification" in json_ld

        # OpenSearchå‡ºåŠ›æ¤œè¨¼
        assert "opensearch" in exported_data
        opensearch = exported_data["opensearch"]
        assert "mappings" in opensearch
        assert "properties" in opensearch["mappings"]
        
        # æ—¥æœ¬èªè§£æå™¨ã®è¨­å®šç¢ºèª
        settings = opensearch.get("settings", {})
        analysis = settings.get("index", {}).get("analysis", {})
        assert "japanese_analyzer" in analysis.get("analyzer", {})

        # PLaMo-readyå‡ºåŠ›æ¤œè¨¼
        assert "plamo-ready" in exported_data
        plamo_config = exported_data["plamo-ready"]
        assert plamo_config["model_config"]["model_name"] == "PLaMo-Embedding-1B"
        assert plamo_config["model_config"]["embedding_dimension"] == 1024
        assert "entity_enhancement" in plamo_config

    def test_business_data_pipeline(self, business_data):
        """ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""
        basic_metadata = {
            "source_info": {"file_path": "projects.json"},
            "processing_timestamp": "2024-06-07T10:00:00Z",
            "rag_version": "2.0.0"
        }

        # é«˜åº¦ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        advanced_metadata = self.advanced_generator.generate_advanced_metadata(
            json_data=business_data,
            basic_metadata=basic_metadata
        )

        # ãƒ“ã‚¸ãƒã‚¹ç”¨èªã®æ¤œå‡ºæ¤œè¨¼
        business_terms = advanced_metadata.entity_classification.business_terms
        expected_terms = ["æ ªå¼ä¼šç¤¾", "æœ‰é™ä¼šç¤¾"]
        detected_terms = [term.term for term in business_terms]
        
        for expected in expected_terms:
            assert any(expected in term for term in detected_terms)

        # ä¾¡æ ¼åˆ†ææ¤œè¨¼
        price_stats = advanced_metadata.statistical_analysis["numerical_fields"].get("price")
        assert price_stats is not None
        assert price_stats["min_value"] == 800000
        assert price_stats["max_value"] == 5000000

        # ãƒ•ã‚¡ã‚»ãƒƒãƒˆç”Ÿæˆ
        facets = self.facet_generator.generate_facets(advanced_metadata)
        
        # ä¾¡æ ¼ç¯„å›²ãƒ•ã‚¡ã‚»ãƒƒãƒˆæ¤œè¨¼
        price_facet = next(
            (f for f in facets.numerical_facets if f.field_name == "price"),
            None
        )
        assert price_facet is not None
        assert len(price_facet.ranges) >= 3  # é©åˆ‡ãªç¯„å›²åˆ†å‰²

        # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚¡ã‚»ãƒƒãƒˆæ¤œè¨¼
        category_facet = next(
            (f for f in facets.categorical_facets if f.field_name == "category"),
            None
        )
        assert category_facet is not None
        assert "IT ã‚µãƒ¼ãƒ“ã‚¹" in category_facet.values

    def test_performance_large_dataset(self):
        """å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        import time

        # 1000ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        large_dataset = []
        for i in range(1000):
            large_dataset.append({
                "id": i,
                "name": f"ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼{i}",
                "category": f"ã‚«ãƒ†ã‚´ãƒª{i % 10}",
                "value": i * 1000,
                "date": f"2024-{(i % 12) + 1:02d}-01",
                "description": f"ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿{i}ã®èª¬æ˜ã§ã™ã€‚"
            })

        basic_metadata = {"source_info": {"file_path": "large_test.json"}}

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
        start_time = time.time()
        
        advanced_metadata = self.advanced_generator.generate_advanced_metadata(
            json_data=large_dataset,
            basic_metadata=basic_metadata
        )
        
        facets = self.facet_generator.generate_facets(advanced_metadata)
        
        exported = self.metadata_exporter.export_metadata(
            advanced_metadata=advanced_metadata,
            generated_facets=facets,
            formats=["opensearch", "plamo-ready"]
        )
        
        processing_time = time.time() - start_time
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼ï¼ˆ30ç§’ä»¥å†…ã§å®Œäº†ã™ã‚‹ã“ã¨ï¼‰
        assert processing_time < 30.0
        
        # çµæœã®å¦¥å½“æ€§æ¤œè¨¼
        assert len(facets.categorical_facets) > 0
        assert len(facets.numerical_facets) > 0
        assert "opensearch" in exported
        assert "plamo-ready" in exported

    def test_error_handling_invalid_data(self):
        """ä¸æ­£ãƒ‡ãƒ¼ã‚¿ã§ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        # ç©ºãƒ‡ãƒ¼ã‚¿
        advanced_metadata = self.advanced_generator.generate_advanced_metadata(
            json_data=[],
            basic_metadata={}
        )
        assert advanced_metadata is not None
        assert advanced_metadata.data_quality.overall_score >= 0.0

        # ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ 
        invalid_data = [
            {"valid_field": "value"},
            None,
            {"another_field": 123},
            {"mixed": [1, 2, "three"]}
        ]
        
        advanced_metadata = self.advanced_generator.generate_advanced_metadata(
            json_data=invalid_data,
            basic_metadata={}
        )
        
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å‡¦ç†ã¯å®Œäº†ã™ã‚‹ã“ã¨
        assert advanced_metadata is not None
        
        # å“è³ªã‚¹ã‚³ã‚¢ãŒå¦¥å½“ãªç¯„å›²ã§ã‚ã‚‹ã“ã¨
        quality_score = advanced_metadata.data_quality.overall_score
        assert 0.0 <= quality_score <= 1.0

    def test_file_integration_test(self, japanese_employee_data):
        """ãƒ•ã‚¡ã‚¤ãƒ«çµŒç”±ã§ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            json.dump(japanese_employee_data, f, ensure_ascii=False, indent=2)
            temp_file_path = f.name

        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚“ã§å‡¦ç†
            with open(temp_file_path, 'r', encoding='utf-8') as f:
                loaded_data = json.load(f)

            basic_metadata = {
                "source_info": {"file_path": temp_file_path},
                "processing_timestamp": "2024-06-07T10:00:00Z"
            }

            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
            advanced_metadata = self.advanced_generator.generate_advanced_metadata(
                json_data=loaded_data,
                basic_metadata=basic_metadata
            )

            facets = self.facet_generator.generate_facets(advanced_metadata)

            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æƒ…å ±ã®ä¿æŒç¢ºèª
            assert temp_file_path in str(advanced_metadata.basic_metadata)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›ã«ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ãŒå«ã¾ã‚Œã‚‹ã“ã¨
            exported = self.metadata_exporter.export_metadata(
                advanced_metadata=advanced_metadata,
                generated_facets=facets,
                formats=["json-ld"]
            )
            
            json_ld = exported["json-ld"]
            assert temp_file_path in json_ld["name"]

        finally:
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            Path(temp_file_path).unlink()

    def test_multilingual_support(self):
        """å¤šè¨€èªå¯¾å¿œãƒ†ã‚¹ãƒˆï¼ˆæ—¥æœ¬èª + è‹±èªï¼‰"""
        mixed_data = [
            {
                "name": "ç”°ä¸­å¤ªéƒ",
                "english_name": "Taro Tanaka",
                "department": "Engineering",
                "éƒ¨ç½²": "é–‹ç™ºéƒ¨",
                "skills": ["Python", "æ©Ÿæ¢°å­¦ç¿’", "Machine Learning"],
                "location": "Tokyo, Japan"
            },
            {
                "name": "John Smith",
                "japanese_name": "ã‚¸ãƒ§ãƒ³ãƒ»ã‚¹ãƒŸã‚¹",
                "department": "Sales",
                "éƒ¨ç½²": "å–¶æ¥­éƒ¨",
                "skills": ["Salesforce", "CRM", "å–¶æ¥­æˆ¦ç•¥"],
                "location": "New York, USA"
            }
        ]

        basic_metadata = {"source_info": {"file_path": "multilingual.json"}}

        advanced_metadata = self.advanced_generator.generate_advanced_metadata(
            json_data=mixed_data,
            basic_metadata=basic_metadata
        )

        # æ—¥æœ¬èªåãƒ»è‹±èªåä¸¡æ–¹ã®æ¤œå‡ºç¢ºèª
        persons = advanced_metadata.entity_classification.persons
        person_names = [p.name for p in persons]
        
        # æ—¥æœ¬èªåãŒæ¤œå‡ºã•ã‚Œã‚‹ã“ã¨
        japanese_names = [name for name in person_names if any(char >= '\u3040' for char in name)]
        assert len(japanese_names) >= 1

        # çµ„ç¹”åï¼ˆéƒ¨ç½²ï¼‰ã®æ¤œå‡º
        organizations = advanced_metadata.entity_classification.organizations
        org_names = [o.organization for o in organizations]
        
        # æ—¥æœ¬èªéƒ¨ç½²åãŒæ¤œå‡ºã•ã‚Œã‚‹ã“ã¨
        assert any("éƒ¨" in org for org in org_names)

    def test_facet_ui_configuration(self, japanese_employee_data):
        """ãƒ•ã‚¡ã‚»ãƒƒãƒˆUIè¨­å®šã®æ¤œè¨¼"""
        basic_metadata = {"source_info": {"file_path": "ui_test.json"}}

        advanced_metadata = self.advanced_generator.generate_advanced_metadata(
            json_data=japanese_employee_data,
            basic_metadata=basic_metadata
        )

        facets = self.facet_generator.generate_facets(advanced_metadata)

        # çµ¦ä¸ãƒ•ã‚¡ã‚»ãƒƒãƒˆã®UIè¨­å®šæ¤œè¨¼
        salary_facet = next(
            (f for f in facets.numerical_facets if f.field_name == "salary"),
            None
        )
        assert salary_facet is not None
        
        ui_config = salary_facet.ui_config
        assert ui_config["widget_type"] == "range_slider"
        assert ui_config["number_format"] == "currency"
        assert ui_config["currency_symbol"] == "Â¥"

        # å¹´é½¢ãƒ•ã‚¡ã‚»ãƒƒãƒˆã®UIè¨­å®šæ¤œè¨¼
        age_facet = next(
            (f for f in facets.numerical_facets if f.field_name == "age"),
            None
        )
        assert age_facet is not None
        
        age_ui_config = age_facet.ui_config
        assert age_ui_config["number_format"] == "integer"
        assert age_ui_config["suffix"] == "æ­³"

        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ•ã‚¡ã‚»ãƒƒãƒˆã®UIè¨­å®šæ¤œè¨¼
        person_facet = next(
            (f for f in facets.entity_facets if f.entity_type == "persons"),
            None
        )
        assert person_facet is not None
        
        person_ui_config = person_facet.ui_config
        assert person_ui_config["icon"] == "ğŸ‘¤"
        assert "color" in person_ui_config
        assert person_ui_config["displayFormat"] == "name_with_confidence"

    def test_export_format_completeness(self, japanese_employee_data):
        """å…¨å‡ºåŠ›å½¢å¼ã®å®Œå…¨æ€§ãƒ†ã‚¹ãƒˆ"""
        basic_metadata = {"source_info": {"file_path": "export_test.json"}}

        advanced_metadata = self.advanced_generator.generate_advanced_metadata(
            json_data=japanese_employee_data,
            basic_metadata=basic_metadata
        )

        facets = self.facet_generator.generate_facets(advanced_metadata)

        # å…¨å½¢å¼ã§ã®å‡ºåŠ›ãƒ†ã‚¹ãƒˆ
        all_formats = ["json-ld", "opensearch", "elasticsearch", "plamo-ready", "search-config", "facet-config"]
        exported = self.metadata_exporter.export_metadata(
            advanced_metadata=advanced_metadata,
            generated_facets=facets,
            formats=all_formats
        )

        # å…¨å½¢å¼ãŒæ­£å¸¸ã«å‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨
        for format_name in all_formats:
            assert format_name in exported
            assert isinstance(exported[format_name], dict)
            assert len(exported[format_name]) > 0

        # Elasticsearchç‰¹æœ‰ã®è¨­å®šç¢ºèª
        elasticsearch = exported["elasticsearch"]
        assert "embedding_vector" in elasticsearch["mappings"]["properties"]
        assert elasticsearch["mappings"]["properties"]["embedding_vector"]["dims"] == 1024

        # PLaMo-readyå½¢å¼ã®è©³ç´°ç¢ºèª
        plamo_ready = exported["plamo-ready"]
        assert plamo_ready["model_config"]["embedding_dimension"] == 1024
        assert plamo_ready["model_config"]["max_sequence_length"] == 512
        assert "japanese_optimization" in plamo_ready["preprocessing_config"]

        # æ¤œç´¢è¨­å®šã®ç¢ºèª
        search_config = exported["search-config"]
        assert "facet_settings" in search_config
        assert "suggestion_config" in search_config
        assert search_config["suggestion_config"]["japanese_reading_support"] is True

        # ãƒ•ã‚¡ã‚»ãƒƒãƒˆè¨­å®šã®ç¢ºèª
        facet_config = exported["facet-config"]
        assert facet_config["display_config"]["localization"] == "ja_JP"
        assert "facet_groups" in facet_config