# Phase 2: AdvancedMetadataGenerator ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ

## æ±ºå®šæ—¥æ™‚
2025å¹´6æœˆ7æ—¥ - Phase 2é–‹å§‹

## èƒŒæ™¯ãƒ»ç›®çš„
Phase 1ã§åŸºæœ¬çš„ãªRAGãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãŒå®Œæˆã€‚Phase 2ã§ã¯ã€æ—¥æœ¬èªå¯¾å¿œã®é«˜åº¦ãªçµ±è¨ˆåˆ†æãƒ»ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åˆ†é¡ãƒ»æ¤œç´¢ãƒ•ã‚¡ã‚»ãƒƒãƒˆç”Ÿæˆæ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã€PLaMo-Embedding-1Bçµ±åˆã¸ã®æº–å‚™ã‚’å®Œäº†ã™ã‚‹ã€‚

## Phase 2ã®æ ¸å¿ƒç›®æ¨™

### ğŸ¯ æ—¥æœ¬èªç‰¹åŒ–RAGã‚·ã‚¹ãƒ†ãƒ ã®é«˜åº¦åŒ–
1. **çµ±è¨ˆåˆ†æã®æ·±åŒ–**: åŸºæœ¬çµ±è¨ˆã‹ã‚‰é«˜åº¦ãªåˆ†å¸ƒåˆ†æãƒ»ç›¸é–¢åˆ†æã¸
2. **æ—¥æœ¬èªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£èªè­˜**: åå‰ãƒ»å ´æ‰€ãƒ»çµ„ç¹”ã®è‡ªå‹•åˆ†é¡
3. **æ¤œç´¢ãƒ•ã‚¡ã‚»ãƒƒãƒˆè‡ªå‹•ç”Ÿæˆ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“å‘ä¸Š
4. **å¤šå½¢å¼ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›**: JSON-LDã€OpenSearchã€Elasticsearchå¯¾å¿œ

---

## AdvancedMetadataGenerator è¨­è¨ˆä»•æ§˜

### ã‚¯ãƒ©ã‚¹æ§‹é€ è¨­è¨ˆ

```python
class AdvancedMetadataGenerator:
    """
    Phase 2: é«˜åº¦ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆæ©Ÿèƒ½
    
    Phase 1ã®RAGMetadataExtractorã‚’æ‹¡å¼µã—ã€ä»¥ä¸‹ã‚’è¿½åŠ :
    - é«˜åº¦çµ±è¨ˆåˆ†æ (åˆ†å¸ƒã€ç›¸é–¢ã€å¤–ã‚Œå€¤æ¤œå‡º)
    - æ—¥æœ¬èªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åˆ†é¡ (äººåã€åœ°åã€çµ„ç¹”å)
    - ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡ (å®Œå…¨æ€§ã€ä¸€è²«æ€§ã€å¦¥å½“æ€§)
    - PLaMo-Embedding-1Bé€£æºæº–å‚™
    """
    
    def __init__(self, config: AdvancedConfig):
        self.statistical_analyzer = StatisticalAnalyzer()
        self.japanese_entity_classifier = JapaneseEntityClassifier()
        self.data_quality_assessor = DataQualityAssessor()
        self.plamo_preparation = PLaMoPreparationLayer()
    
    def generate_advanced_metadata(
        self, 
        json_data: Any, 
        basic_metadata: dict,
        context: AnalysisContext
    ) -> AdvancedMetadata:
        """é«˜åº¦ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        
        return AdvancedMetadata(
            statistical_analysis=self._analyze_statistics(json_data),
            entity_classification=self._classify_entities(json_data),
            data_quality=self._assess_quality(json_data),
            search_optimization=self._optimize_for_search(json_data),
            plamo_features=self._prepare_plamo_features(json_data)
        )
```

### 1. StatisticalAnalyzer (çµ±è¨ˆåˆ†æå™¨)

```python
class StatisticalAnalyzer:
    """é«˜åº¦çµ±è¨ˆåˆ†ææ©Ÿèƒ½"""
    
    def analyze_numerical_data(self, data: list) -> NumericalStats:
        """æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°åˆ†æ"""
        return NumericalStats(
            descriptive_stats=self._calculate_descriptive_stats(data),
            distribution_analysis=self._analyze_distribution(data),
            outlier_detection=self._detect_outliers(data),
            correlation_matrix=self._calculate_correlations(data)
        )
    
    def analyze_categorical_data(self, data: list) -> CategoricalStats:
        """ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ã®åˆ†æ"""
        return CategoricalStats(
            frequency_distribution=self._calculate_frequencies(data),
            entropy=self._calculate_entropy(data),
            diversity_index=self._calculate_diversity(data),
            pattern_detection=self._detect_patterns(data)
        )
    
    def analyze_temporal_data(self, data: list) -> TemporalStats:
        """æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ"""
        return TemporalStats(
            time_range=self._extract_time_range(data),
            seasonal_patterns=self._detect_seasonal_patterns(data),
            trend_analysis=self._analyze_trends(data),
            frequency_patterns=self._analyze_frequency(data)
        )
```

### 2. JapaneseEntityClassifier (æ—¥æœ¬èªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åˆ†é¡å™¨)

```python
class JapaneseEntityClassifier:
    """æ—¥æœ¬èªç‰¹åŒ–ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£èªè­˜ãƒ»åˆ†é¡"""
    
    def __init__(self):
        # æ—¥æœ¬èªç‰¹åŒ–ã®æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.person_patterns = self._load_person_patterns()
        self.place_patterns = self._load_place_patterns()
        self.organization_patterns = self._load_organization_patterns()
        self.business_patterns = self._load_business_patterns()
    
    def classify_entities(self, text_data: list[str]) -> EntityClassification:
        """ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’åˆ†é¡"""
        entities = EntityClassification()
        
        for text in text_data:
            # äººåã®æ¤œå‡º
            persons = self._extract_persons(text)
            entities.persons.extend(persons)
            
            # å ´æ‰€åã®æ¤œå‡º
            places = self._extract_places(text)
            entities.places.extend(places)
            
            # çµ„ç¹”åã®æ¤œå‡º
            organizations = self._extract_organizations(text)
            entities.organizations.extend(organizations)
            
            # æ—¥æœ¬èªç‰¹æœ‰ã®ãƒ“ã‚¸ãƒã‚¹ç”¨èª
            business_terms = self._extract_business_terms(text)
            entities.business_terms.extend(business_terms)
        
        return entities
    
    def _extract_persons(self, text: str) -> list[PersonEntity]:
        """æ—¥æœ¬èªäººåã®æŠ½å‡º"""
        # ä¸€èˆ¬çš„ãªæ—¥æœ¬èªå§“åãƒ‘ã‚¿ãƒ¼ãƒ³
        patterns = [
            r'[ä¸€-é¾¯]{1,4}[ä¸€-é¾¯]{1,3}',  # æ¼¢å­—å§“å
            r'[ã‚¢-ãƒ³]{2,8}',               # ã‚«ã‚¿ã‚«ãƒŠå
            r'[a-zA-Z]{2,20}\s[a-zA-Z]{2,20}'  # è‹±èªå
        ]
        # å®Ÿè£…è©³ç´°ã¯çœç•¥
        pass
    
    def _extract_places(self, text: str) -> list[PlaceEntity]:
        """æ—¥æœ¬èªåœ°åã®æŠ½å‡º"""
        # éƒ½é“åºœçœŒã€å¸‚åŒºç”ºæ‘ã€é§…åç­‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        prefecture_pattern = r'[ä¸€-é¾¯]{2,3}[éƒ½é“åºœçœŒ]'
        city_pattern = r'[ä¸€-é¾¯]{1,8}[å¸‚åŒºç”ºæ‘]'
        # å®Ÿè£…è©³ç´°ã¯çœç•¥
        pass
```

### 3. DataQualityAssessor (ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡å™¨)

```python
class DataQualityAssessor:
    """ãƒ‡ãƒ¼ã‚¿å“è³ªã®å¤šè§’çš„è©•ä¾¡"""
    
    def assess_data_quality(self, data: Any) -> DataQualityReport:
        """åŒ…æ‹¬çš„ãªãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡"""
        return DataQualityReport(
            completeness=self._assess_completeness(data),
            consistency=self._assess_consistency(data),
            validity=self._assess_validity(data),
            accuracy=self._assess_accuracy(data),
            uniqueness=self._assess_uniqueness(data)
        )
    
    def _assess_completeness(self, data: Any) -> CompletenessScore:
        """ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§ã®è©•ä¾¡"""
        return CompletenessScore(
            null_rate=self._calculate_null_rate(data),
            empty_string_rate=self._calculate_empty_rate(data),
            missing_field_rate=self._calculate_missing_fields(data),
            overall_score=self._calculate_completeness_score(data)
        )
    
    def _assess_consistency(self, data: Any) -> ConsistencyScore:
        """ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§ã®è©•ä¾¡"""
        return ConsistencyScore(
            format_consistency=self._check_format_consistency(data),
            value_consistency=self._check_value_consistency(data),
            schema_consistency=self._check_schema_consistency(data),
            overall_score=self._calculate_consistency_score(data)
        )
```

---

## SearchFacetGenerator è¨­è¨ˆä»•æ§˜

### è‡ªå‹•ãƒ•ã‚¡ã‚»ãƒƒãƒˆç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯

```python
class SearchFacetGenerator:
    """æ¤œç´¢ãƒ•ã‚¡ã‚»ãƒƒãƒˆã®è‡ªå‹•ç”Ÿæˆ"""
    
    def generate_facets(self, metadata: AdvancedMetadata) -> SearchFacets:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¤œç´¢ãƒ•ã‚¡ã‚»ãƒƒãƒˆã‚’è‡ªå‹•ç”Ÿæˆ"""
        facets = SearchFacets()
        
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ•ã‚¡ã‚»ãƒƒãƒˆ
        facets.categorical = self._generate_categorical_facets(metadata)
        
        # æ•°å€¤ç¯„å›²ãƒ•ã‚¡ã‚»ãƒƒãƒˆ
        facets.numerical = self._generate_numerical_facets(metadata)
        
        # æ™‚é–“ç¯„å›²ãƒ•ã‚¡ã‚»ãƒƒãƒˆ
        facets.temporal = self._generate_temporal_facets(metadata)
        
        # æ—¥æœ¬èªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ•ã‚¡ã‚»ãƒƒãƒˆ
        facets.entities = self._generate_entity_facets(metadata)
        
        return facets
    
    def _generate_categorical_facets(self, metadata: AdvancedMetadata) -> dict:
        """ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ•ã‚¡ã‚»ãƒƒãƒˆç”Ÿæˆ"""
        facets = {}
        
        for field, stats in metadata.categorical_stats.items():
            if stats.unique_count <= 50:  # ãƒ•ã‚¡ã‚»ãƒƒãƒˆåŒ–é©æ­£å€¤
                facets[field] = {
                    "type": "terms",
                    "values": stats.value_counts,
                    "display_name": self._generate_display_name(field)
                }
        
        return facets
    
    def _generate_numerical_facets(self, metadata: AdvancedMetadata) -> dict:
        """æ•°å€¤ç¯„å›²ãƒ•ã‚¡ã‚»ãƒƒãƒˆç”Ÿæˆ"""
        facets = {}
        
        for field, stats in metadata.numerical_stats.items():
            ranges = self._calculate_optimal_ranges(stats)
            facets[field] = {
                "type": "range",
                "ranges": ranges,
                "min": stats.min_value,
                "max": stats.max_value,
                "display_name": self._generate_display_name(field)
            }
        
        return facets
```

---

## MetadataExporter è¨­è¨ˆä»•æ§˜

### å¤šå½¢å¼å‡ºåŠ›å¯¾å¿œ

```python
class MetadataExporter:
    """å¤šå½¢å¼ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›"""
    
    def export_metadata(
        self, 
        metadata: AdvancedMetadata, 
        formats: list[str]
    ) -> dict[str, Any]:
        """æŒ‡å®šå½¢å¼ã§ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›"""
        exports = {}
        
        for format_type in formats:
            if format_type == "json-ld":
                exports["json-ld"] = self._export_json_ld(metadata)
            elif format_type == "opensearch":
                exports["opensearch"] = self._export_opensearch(metadata)
            elif format_type == "elasticsearch":
                exports["elasticsearch"] = self._export_elasticsearch(metadata)
            elif format_type == "plamo-ready":
                exports["plamo-ready"] = self._export_plamo_ready(metadata)
        
        return exports
    
    def _export_json_ld(self, metadata: AdvancedMetadata) -> dict:
        """JSON-LDå½¢å¼ã§ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›"""
        return {
            "@context": {
                "@vocab": "http://schema.org/",
                "rag": "http://example.com/rag-schema/"
            },
            "@type": "Dataset",
            "name": metadata.dataset_info.name,
            "description": metadata.dataset_info.description,
            "rag:statisticalAnalysis": metadata.statistical_analysis,
            "rag:entityClassification": metadata.entity_classification,
            "rag:dataQuality": metadata.data_quality,
            "rag:searchFacets": metadata.search_facets
        }
    
    def _export_opensearch(self, metadata: AdvancedMetadata) -> dict:
        """OpenSearchç”¨ãƒãƒƒãƒ”ãƒ³ã‚°å®šç¾©ç”Ÿæˆ"""
        mapping = {
            "mappings": {
                "properties": {}
            }
        }
        
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å‹ã®è‡ªå‹•ãƒãƒƒãƒ”ãƒ³ã‚°
        for field, field_metadata in metadata.field_analysis.items():
            if field_metadata.data_type == "text":
                mapping["mappings"]["properties"][field] = {
                    "type": "text",
                    "analyzer": "japanese",  # æ—¥æœ¬èªå¯¾å¿œ
                    "fields": {
                        "keyword": {
                            "type": "keyword"
                        }
                    }
                }
            elif field_metadata.data_type == "number":
                mapping["mappings"]["properties"][field] = {
                    "type": "integer" if field_metadata.is_integer else "float"
                }
        
        return mapping
```

---

## PLaMo-Embedding-1Bé€£æºæº–å‚™

### PLaMoPreparationLayerè¨­è¨ˆ

```python
class PLaMoPreparationLayer:
    """PLaMo-Embedding-1Bçµ±åˆã¸ã®æº–å‚™æ©Ÿèƒ½"""
    
    def prepare_for_plamo(self, metadata: AdvancedMetadata) -> PLaMoFeatures:
        """PLaMo-Embedding-1Bç”¨ã®ç‰¹å¾´é‡æº–å‚™"""
        return PLaMoFeatures(
            text_segments=self._extract_text_segments(metadata),
            japanese_specific_features=self._extract_japanese_features(metadata),
            embedding_hints=self._generate_embedding_hints(metadata),
            vector_optimization=self._prepare_vector_optimization(metadata)
        )
    
    def _extract_japanese_features(self, metadata: AdvancedMetadata) -> JapaneseFeatures:
        """æ—¥æœ¬èªç‰¹æœ‰ã®ç‰¹å¾´é‡æŠ½å‡º"""
        return JapaneseFeatures(
            kanji_density=self._calculate_kanji_density(metadata),
            katakana_terms=self._extract_katakana_terms(metadata),
            business_terminology=self._extract_business_terms(metadata),
            honorific_patterns=self._analyze_honorifics(metadata)
        )
```

---

## ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹å®šç¾©

```python
@dataclass
class AdvancedMetadata:
    """Phase 2é«˜åº¦ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ§‹é€ """
    basic_metadata: dict  # Phase 1ã‹ã‚‰ã®ç¶™æ‰¿
    statistical_analysis: StatisticalAnalysis
    entity_classification: EntityClassification
    data_quality: DataQualityReport
    search_facets: SearchFacets
    export_formats: dict[str, Any]
    plamo_features: PLaMoFeatures

@dataclass
class StatisticalAnalysis:
    """çµ±è¨ˆåˆ†æçµæœ"""
    numerical_stats: dict[str, NumericalStats]
    categorical_stats: dict[str, CategoricalStats]
    temporal_stats: dict[str, TemporalStats]
    correlation_matrix: np.ndarray
    outlier_analysis: OutlierAnalysis

@dataclass
class EntityClassification:
    """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åˆ†é¡çµæœ"""
    persons: list[PersonEntity]
    places: list[PlaceEntity]
    organizations: list[OrganizationEntity]
    business_terms: list[BusinessTermEntity]
    confidence_scores: dict[str, float]

@dataclass  
class DataQualityReport:
    """ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ"""
    completeness: CompletenessScore
    consistency: ConsistencyScore
    validity: ValidityScore
    accuracy: AccuracyScore
    overall_score: float
```

---

## å®Ÿè£…å„ªå…ˆåº¦ã¨ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³

### Week 1: åŸºç›¤å®Ÿè£…
1. **AdvancedMetadataGeneratoråŸºæœ¬ã‚¯ãƒ©ã‚¹** (2æ—¥)
2. **StatisticalAnalyzerå®Ÿè£…** (2æ—¥)
3. **æ—¢å­˜Phase 1ã¨ã®çµ±åˆãƒ†ã‚¹ãƒˆ** (1æ—¥)

### Week 2: æ—¥æœ¬èªå¯¾å¿œå®Ÿè£…
1. **JapaneseEntityClassifierå®Ÿè£…** (3æ—¥)
2. **DataQualityAssessorå®Ÿè£…** (2æ—¥)

### Week 3: æ¤œç´¢ãƒ»å‡ºåŠ›æ©Ÿèƒ½
1. **SearchFacetGeneratorå®Ÿè£…** (2æ—¥)
2. **MetadataExporterå®Ÿè£…** (2æ—¥)
3. **åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆä½œæˆ** (1æ—¥)

### Week 4: PLaMoæº–å‚™ãƒ»æœ€é©åŒ–
1. **PLaMoPreparationLayerå®Ÿè£…** (2æ—¥)
2. **æ€§èƒ½æœ€é©åŒ–ãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯** (2æ—¥)
3. **Phase 3æº–å‚™å®Œäº†** (1æ—¥)

---

## æŠ€è¡“çš„è€ƒæ…®äº‹é …

### æ€§èƒ½æœ€é©åŒ–
- **é…å»¶è©•ä¾¡**: å¿…è¦ãªåˆ†æã®ã¿å®Ÿè¡Œ
- **ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°**: è¨ˆç®—çµæœã®åŠ¹ç‡çš„ã‚­ãƒ£ãƒƒã‚·ãƒ¥
- **ä¸¦åˆ—å‡¦ç†**: ç‹¬ç«‹åˆ†æã®ä¸¦è¡Œå®Ÿè¡Œ

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- **æ®µéšçš„ç¸®é€€**: ä¸€éƒ¨åˆ†æå¤±æ•—æ™‚ã®å®‰å…¨ãªå‹•ä½œ
- **ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™**: ãƒ¡ãƒ¢ãƒªãƒ»æ™‚é–“åˆ¶é™ã®å³æ ¼ç®¡ç†
- **ãƒ­ã‚°è¨˜éŒ²**: è©³ç´°ãªåˆ†æãƒ­ã‚°ã®å‡ºåŠ›

### æ‹¡å¼µæ€§ç¢ºä¿
- **ãƒ—ãƒ©ã‚°ã‚¤ãƒ³å½¢å¼**: æ–°ã—ã„åˆ†æå™¨ã®å®¹æ˜“ãªè¿½åŠ 
- **è¨­å®šé§†å‹•**: åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¤–éƒ¨è¨­å®š
- **APIä¸€è²«æ€§**: Phase 1ã¨ã®ä¸€è²«ã—ãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

---

## æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

1. **AdvancedMetadataGeneratoråŸºæœ¬å®Ÿè£…é–‹å§‹**
2. **StatisticalAnalyzerè©³ç´°è¨­è¨ˆ**
3. **æ—¥æœ¬èªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ‘ã‚¿ãƒ¼ãƒ³åé›†**
4. **PLaMo-Embedding-1Bé€£æºä»•æ§˜è©³ç´°åŒ–**

---

**æ‰¿èªçŠ¶æ³**: Phase 2è¨­è¨ˆæ‰¿èªæ¸ˆã¿
**å®Ÿè£…é–‹å§‹**: å³åº§ã«é–‹å§‹å¯èƒ½
**ç›®æ¨™**: 4é€±é–“ã§Phase 2å®Œå…¨å®Ÿè£…å®Œäº†

ã“ã®è¨­è¨ˆã«ã‚ˆã‚Šã€ä¸–ç•Œæœ€é«˜ãƒ¬ãƒ™ãƒ«ã®æ—¥æœ¬èªç‰¹åŒ–RAGã‚·ã‚¹ãƒ†ãƒ ã®åŸºç›¤ãŒå®Œæˆã—ã¾ã™ã€‚